准备训练脚本
------------

收集神经网络性能数据有两种方式，可以使用以下任意一种方式使能Profiler。

方式一：修改训练脚本
~~~~~~~~~~~~~~~~~~~~

在训练脚本中添加MindSpore Profiler相关接口。

- 在训练开始前，初始化MindSpore ``Profiler``\ 对象，Profiler开启收集性能数据。

  .. note::
     Profiler支持的参数可以参考：
     `Profiler API <https://www.mindspore.cn/docs/zh-CN/master/api_python/mindspore/mindspore.Profiler.html#mindspore.Profiler>`_ 。
     Profiler初始化之前需要确定device_id。

- 在训练结束后，调用\ ``Profiler.analyse()``\ 停止性能数据收集并生成性能分析结果。

**按条件开启样例：**

用户可以通过设置初始化参数start_profile为False来决定暂时不开启Profiler，然后通过调用start函数来在适当的时机开启Profiler，再调用stop函数停止收集数据，最后调用analyse解析数据。
可以是基于epoch或者step开启和关闭Profiler，只收集指定step区间或者epoch区间的数据。基于step或者基于epoch性能数据的收集有两种方式，一种是用户自定义训练，另一种是借助Callback基于step或者epoch开启关闭Profiler。

- 自定义训练：

  MindSpore函数式编程用例使用Profiler进行自定义训练，可以在指定的step区间或者epoch区间开启或者关闭收集Profiler性能数据。`基于step开启Profiler完整代码样例 <https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_step.py>`_。

  .. code:: python

     profiler = ms.Profiler(start_profile=False)
     data_loader = ds.create_dict_iterator()

     for i, data in enumerate(data_loader):
         train()
         if i==100:
             profiler.start()
         if i==200:
             profiler.stop()

     profiler.analyse()

- 自定义Callback

  - 对于数据非下沉模式，只有在每个step结束后才有机会告知CANN开启和停止，因此需要基于step开启和关闭。
    `自定义Callback基于step开启Profiler完整代码样例 <https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_feed_step.py>`_。

    .. code:: python

       import mindspore as ms

       class StopAtStep(ms.Callback):
           def __init__(self, start_step, stop_step):
               super(StopAtStep, self).__init__()
               self.start_step = start_step
               self.stop_step = stop_step
               self.profiler = ms.Profiler(start_profile=False, output_path='./data_step')

           def on_train_step_begin(self, run_context):
               cb_params = run_context.original_args()
               step_num = cb_params.cur_step_num
               if step_num == self.start_step:
                   self.profiler.start()

           def on_train_step_end(self, run_context):
               cb_params = run_context.original_args()
               step_num = cb_params.cur_step_num
               if step_num == self.stop_step:
                   self.profiler.stop()
                   self.profiler.analyse()

  - 对于数据下沉模式，只有在每个epoch结束后才有机会告知CANN开启和停止，因此需要基于epoch开启和关闭。可根据自定义Callback基于step开启Profiler样例代码修改训练脚本。

    .. code:: python

       class StopAtEpoch(ms.Callback):
           def __init__(self, start_epoch, stop_epoch):
               super(StopAtEpoch, self).__init__()
               self.start_epoch = start_epoch
               self.stop_epoch = stop_epoch
               self.profiler = ms.Profiler(start_profile=False, output_path='./data_epoch')

           def on_train_epoch_begin(self, run_context):
               cb_params = run_context.original_args()
               epoch_num = cb_params.cur_epoch_num
               if epoch_num == self.start_epoch:
                   self.profiler.start()

           def on_train_epoch_end(self, run_context):
               cb_params = run_context.original_args()
               epoch_num = cb_params.cur_epoch_num
               if epoch_num == self.stop_epoch:
                   self.profiler.stop()
                   self.profiler.analyse()

**非条件开启样例：**

- 样例一：MindSpore函数式编程用例中使用Profiler收集性能数据，部分样例代码如下所示。`完整代码样例 <https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_sample.py>`_ 。

  .. code:: python

     # Init Profiler.
     # Note that the Profiler should be initialized before model training.
     profiler = Profiler(output_path="profiler_data")

     def forward_fn(data, label):
         logits = model(data)
         loss = loss_fn(logits, label)
         return loss, logits


     # Get gradient function
     grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)


     @ms.jit
     def train_step(data, label):
         """Define function of one-step training"""
         (loss, _), grads = grad_fn(data, label)
         optimizer(grads)
         return loss


     for t in range(epochs):
         train_loop(model, train_dataset, loss_fn, optimizer)

     profiler.analyse()


- 样例二：使用model.train进行网络训练，完整代码如下所示。

  .. code:: python

     import numpy as np
     from mindspore import nn
     from mindspore.train import Model
     import mindspore as ms
     import mindspore.dataset as ds

     class Net(nn.Cell):
         def __init__(self):
             super(Net, self).__init__()
             self.fc = nn.Dense(2, 2)

         def construct(self, x):
             return self.fc(x)


     def generator():
         for i in range(2):
             yield (np.ones([2, 2]).astype(np.float32), np.ones([2]).astype(np.int32))


     def train(net):
         optimizer = nn.Momentum(net.trainable_params(), 1, 0.9)
         loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)
         data = ds.GeneratorDataset(generator, ["data", "label"])
         model = Model(net, loss, optimizer)
         model.train(1, data)


     if __name__ == '__main__':
         ms.set_context(mode=ms.GRAPH_MODE, device_target="Ascend")

         # Init Profiler
         # Note that the Profiler should be initialized before model.train
         profiler = ms.Profiler(output_path='./profiler_data')

         # Train Model
         net = Net()
         train(net)

         # Profiler end
         profiler.analyse()

方式二：环境变量使能
~~~~~~~~~~~~~~~~~~~~

在运行网络脚本前，配置Profiler相关配置项。

说明：

- 使用环境变量使能方式，请在脚本开始执行之前通过环境变量设置好device id。禁止在脚本中通过set_context函数设置device id。

.. code-block:: shell

   export MS_PROFILER_OPTIONS='{"start": true, "output_path": "/XXX", "profile_memory": false, "profile_communication": false, "aicore_metrics": 0, "l2_cache": false}'

- `start` (bool，必选) - 设置为true，表示使能Profiler；设置成false，表示关闭性能数据收集，默认值：false。

- `output_path` (str, 可选) - 表示输出数据的路径（绝对路径）。默认值："./data"。

- `op_time` (bool, 可选) - 表示是否收集算子性能数据，默认值：true。

- `profile_memory` (bool，可选) - 表示是否收集Tensor内存数据。当值为true时，收集这些数据。使用此参数时，`op_time` 必须设置成true。默认值：false。

- `profile_communication` (bool, 可选) - 表示是否在多设备训练中收集通信性能数据。当值为true时，收集这些数据。在单台设备训练中，该参数的设置无效。使用此参数时，`op_time` 必须设置成true。默认值：false。

- `aicore_metrics` (int, 可选) - 设置AI Core指标类型，使用此参数时，`op_time` 必须设置成true。默认值：0。

- `l2_cache` (bool, 可选) - 设置是否收集l2缓存数据，默认值：false。

- `timeline_limit` (int, 可选) - 设置限制timeline文件存储上限大小（单位M），使用此参数时，`op_time` 必须设置成true。默认值：500。

- `data_process` (bool, 可选) - 表示是否收集数据准备性能数据，默认值：true。

- `parallel_strategy` (bool, 可选) - 表示是否收集并行策略性能数据，默认值：true。

- `profile_framework` (str, 可选) - 是否需要收集Host侧的内存和时间，可选参数为["all", "time", null]。默认值："all"。
