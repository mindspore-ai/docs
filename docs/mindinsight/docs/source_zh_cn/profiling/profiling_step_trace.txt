迭代轨迹分析
~~~~~~~~~~~~

使用迭代轨迹分析组件可以快速了解训练各阶段在总时长中的占比情况。迭代轨迹将训练的一个step划分为迭代间隙
(两次step执行的间隔时间)、前向与反向执行、all
reduce、参数更新等几个阶段，并显示出每个阶段的时长，帮助用户定界出性能瓶颈所在的执行阶段。

.. note::
   迭代轨迹目前仅支持Graph模式单图和多子图场景，暂不支持PyNative、异构等场景。
   多子图场景迭代轨迹只展示迭代整体耗时。

.. figure:: ./images/step_trace.png
   :alt: step_trace.png

*图：迭代轨迹分析*

上图展示了迭代轨迹分析页面。在迭代轨迹详情中，会展示各阶段在训练step中的起止时间，默认显示的是各step的平均值，用户也可以在下拉菜单选择某个step查看该step的迭代轨迹情况。

页面下方显示了迭代间隙、前后向计算、迭代拖尾时间随着step的变化曲线等，用户可以据此判断某个阶段是否存在性能优化空间。其中：

- **迭代间隙：**
  主要负责从数据队列中读取数据，如果该部分耗时较长，建议前往数据准备部分进一步分析。
- **前后向计算：**
  执行网络中的前向算子以及反向算子，承载了一个step主要的计算工作，如果该部分耗时较长，建议前往算子统计或时间线中进一步分析。
- **迭代拖尾：**
  主要在多卡场景下执行参数聚合、参数更新操作，包括前后向计算结束到参数更新完成的时间。如果该部分耗时较长，建议查看\ ``all_reduce``\ 耗时以及并行情况。

| 迭代轨迹在做阶段划分时，需要识别前向计算开始的算子和反向计算结束的算子。为了降低用户使用Profiler的门槛，MindSpore会对这两个算子做自动识别，方法为：
| 前向计算开始的算子指定为\ ``get_next``\ 算子之后连接的第一个算子，反向计算结束的算子指定为最后一次all
  reduce之前连接的算子。\ **Profiler不保证在所有情况下自动识别的结果和用户的预期一致，用户可以根据网络的特点自行调整**\ ，调整方法如下：

- 设置\ ``PROFILING_FP_START``\ 环境变量指定前向计算开始的算子，如\ ``export PROFILING_FP_START=fp32_vars/conv2d/BatchNorm``\ 。
- 设置\ ``PROFILING_BP_END``\ 环境变量指定反向计算结束的算子，如\ ``export PROFILING_BP_END=loss_scale/gradients/AddN_70``\ 。
