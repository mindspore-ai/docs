Resource Utilization
--------------------

Resource utilization includes cpu usage analysis and memory usage
analysis.

.. figure:: ./images/resource_visibility.png
   :alt: resource_visibility.png

*Figure:Overview of resource utilization*

Overview of resource utilization：Including CPU utilization analysis and
memory usage analysis. You can view the details by clicking the View
Details button in the upper right corner.

CPU Utilization Analysis
~~~~~~~~~~~~~~~~~~~~~~~~

CPU utilization, which is mainly used to assist performance debugging.
After the performance bottleneck is determined according to the queue
size, the performance can be debugged according to the CPU utilization
(if the user utilization is too low, increase the number of threads; if
the system utilization is too high, decrease the number of threads). CPU
utilization includes CPU utilization of the whole machine, process and
Data pipeline operator.

.. figure:: ./images/device_cpu_utilization.png
   :alt: device_utilization.png

*Figure:CPU utilization of the whole machine*

CPU utilization of the whole machine: Show the overall CPU usage of the
device in the training process, including user utilization, system
utilization, idle utilization, IO utilization, current number of active
processes, and context switching times. If the user utilization is low,
you can try to increase the number of operator threads to increase the
CPU utilization; if the system utilization is high, and the number of
context switching and CPU waiting for processing is large, it indicates
that the number of threads needs to be reduced accordingly.

.. figure:: ./images/process_cpu_utilizaton.png
   :alt: process_cpu_utilization.png

*Figure:Process utilization*

Process utilization: Show the CPU usage of a single process. The
combination of whole machine utilization and process utilization can
determine whether other processes affect the training process.

.. figure:: ./images/data_op_utilization.png
   :alt: data_op_utilization.png

*Figure:Operator utilization*

Operator utilization: Show the CPU utilization of Data pipeline single
operator. We can adjust the number of threads of the corresponding
operator according to the actual situation. If the number of threads is
small and takes up a lot of CPU, you can consider whether you need to
optimize the code.

Common scenarios of CPU utilization:

- According to the queue size, the network debugging personnel can
  judge that the performance of MindData has a bottleneck. They can
  adjust the number of threads by combining the utilization rate of the
  whole machine and the utilization rate of the operator.
- Developers can check the utilization of operators. If an operator
  consumes CPU utilization, they can confirm whether the code needs to
  be optimized.

.. note::
   The default sampling interval is 1000ms. You can change the sampling
   interval through
   ``mindspore.dataset.config.get_monitor_sampling_interval()``. For
   details：

   `dataset API <https://www.mindspore.cn/docs/en/r1.9/api_python/mindspore.dataset.config.html#mindspore.dataset.config.set_monitor_sampling_interval>`_ .

Memory Analysis
~~~~~~~~~~~~~~~

This page is used to show the memory usage of the neural network model
on the **device**, which is an **ideal prediction** based on the
theoretical calculation results. The content of the page includes:

- An overview of the memory usage of the model, including the total
  available memory, peak memory and other information.
- The memory occupied varies in the execution order while the model is
  running.
- The memory usage of each operator is decomposed and displayed in the
  table of ``Operator Memory Allocation``.

.. note::
   Memory Analysis does not support heterogeneous training currently.

.. figure:: ./images/memory.png
   :alt: memory.png

*Figure:Memory Analysis*

Users can obtain the summary of memory usage via the
``Memory Allocation Overview``. In addition, they can obtain more
detailed information from ``Memory Usage``, including:

- **Line Chart**: Changes in model memory usage, including static
  memory, total occupied memory and total available memory.
- **Zooming**: There is a zoom scroll bar under the line chart. Users
  can zoom in or out the line chart by adjusting its size to observe
  more details.
- **FP/BP**: The execution positions of the start of
  ``Forward Propagation`` and the end of ``Backward Propagation`` of
  the model on the line chart.
- **Details of Nodes**: Hovering over the line chart, the information
  of the corresponding execution operator is shown, including the
  execution order of the operator, the name of the operator, the memory
  occupied by the operator, the total memory occupied by the model in
  the current position, and the relative memory change compared with
  the previous execution position.
- **Memory Decomposition**: Left clicking a position on the line chart,
  the memory breakdowns of the execution position is shown in the table
  below the line chart, called ``Operator Memory Allocation``. The
  table shows the memory decomposition of the corresponding execution
  position, i.e., the output tensor of which operators are allocated
  the occupied memory of the current execution position. The module
  provides users with abundant information, including tensor name,
  tensor size, tensor type, data type, shape, format, and the active
  lifetime of tensor memory.

.. figure:: ./images/memory_graphics.png
   :alt: memory_graphics.png

*Figure:Memory Statistics*
