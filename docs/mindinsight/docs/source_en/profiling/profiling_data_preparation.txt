Data Preparation Performance Analysis
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

| The Data preparation performance analysis component is used to analyse
  the execution of data input pipeline for the training. The data input
  pipeline can be divided into three stages:
| the data process pipeline, data transfer from host to device and data
  fetch on device. The component will analyse the performance of each
  stage in detail and display the results.

.. figure:: ./images/minddata_profile.png
   :alt: minddata_profile.png

*Figure:Data Preparation Performance Analysis*

Figure above displays the page of data preparation performance analysis
component. It consists of two tabs: the step gap and the data process.

The step gap page is used to analyse whether there is performance
bottleneck in the three stages. We can get our conclusion from the data
queue graphs:

- The data queue size stands for the queue length when the training
  fetches data from the queue on the device. If the data queue size is
  0, the training will wait until there is data in the queue; If the
  data queue size is greater than 0, the training can get data very
  quickly, and it means data preparation stage is not the bottleneck
  for this training step.
- The host queue size can be used to infer the speed of data process
  and data transfer. If the host queue size is 0, it means we need to
  speed up the data process stage.
- If the size of the host queue is always large and the size of the
  data queue is continuously small, there may be a performance
  bottleneck in data transfer.

.. figure:: ./images/data_op_profile.png
   :alt: data_op_profile.png

*Figure:Data Process Pipeline Analysis*

Figure above displays the page of data process pipeline analysis. The data
queues are used to exchange data between the data processing operators.
The data size of the queues reflect the data consume speed of the
operators, and can be used to infer the bottleneck operator. The queue
usage percentage stands for the average value of data size in queue
divide data queue maximum size, the higher the usage percentage, the
more data that is accumulated in the queue. The graph at the bottom of
the page shows the data processing pipeline operators with the data
queues, the user can click one queue to see how the data size changes
according to the time, and the operators connected to the queue. The
data process pipeline can be analysed as follows:

- When the input queue usage percentage of one operator is high, and
  the output queue usage percentage is low, the operator may be the
  bottleneck.
- For the leftmost operator, if the usage percentage of all the queues
  on the right are low, the operator may be the bottleneck.
- For the rightmost operator, if the usage percentage of all the queues
  on the left are high, the operator may be the bottleneck.

To optimize the performance of data processing operators, there are some
suggestions:

- If the Dataset Operator is the bottleneck, try to increase the
  ``num_parallel_workers``.
- If a GeneratorOp type operator is the bottleneck, try to increase the
  ``num_parallel_workers`` and replace the operator to
  ``MindRecordDataset``.
- If a MapOp type operator is the bottleneck, try to increase the
  ``num_parallel_workers``. If it is a python operator, try to optimize
  the training script.
- If a BatchOp type operator is the bottleneck, try to adjust the size
  of ``prefetch_size``.
