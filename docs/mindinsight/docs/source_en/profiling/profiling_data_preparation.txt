Data Preparation Performance Analysis
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

| The Data preparation performance analysis component is used to analyse
  the execution of data input pipeline for the training. The data input
  pipeline can be divided into three stages:
| the data process pipeline, data transfer from host to device and data
  fetch on device. The component will analyse the performance of each
  stage in detail and display the results.

.. figure:: ./images/minddata_profile.png
   :alt: minddata_profile.png

*Figure:Data Preparation Performance Analysis*

Figure above displays the page of data preparation performance analysis
component. It consists of two tabs: the step gap and the data process.

The step gap page is used to analyse whether there is performance
bottleneck in the three stages. We can get our conclusion from the data
queue graphs:

- The data queue size stands for the queue length when the training
  fetches data from the queue on the device. If the data queue size is
  0, the training will wait until there is data in the queue; If the
  data queue size is greater than 0, the training can get data very
  quickly, and it means data preparation stage is not the bottleneck
  for this training step.
- The host queue size can be used to infer the speed of data process
  and data transfer. If the host queue size is 0, it means we need to
  speed up the data process stage.
- If the size of the host queue is always large and the size of the
  data queue is continuously small, there may be a performance
  bottleneck in data transfer.

.. note::
   The queue size is the value recorded when fetching data, and obtaining the data
   of host queue and data queue is executed asynchronously, so the number of host
   queue steps, data queue steps, and user training steps may be different.

.. figure:: ./images/data_op_profile.png
   :alt: data_op_profile.png

*Figure:Data Process Pipeline Analysis*

Figure above displays the page of data process pipeline analysis. The data
queues are used to exchange data between the data processing operations.
The data size of the queues reflect the data consume speed of the
operations, and can be used to infer the bottleneck operation. The queue
usage percentage stands for the average value of data size in queue
divide data queue maximum size, the higher the usage percentage, the
more data that is accumulated in the queue. The graph at the bottom of
the page shows the data processing pipeline operations with the data
queues, the user can click one queue to see how the data size changes
according to the time, and the operations connected to the queue. The
data process pipeline can be analysed as follows:

- When the input queue usage percentage of one operation is high, and
  the output queue usage percentage is low, the operation may be the
  bottleneck.
- For the leftmost operation, if the usage percentage of all the queues
  on the right are low, the operation may be the bottleneck.
- For the rightmost operation, if the usage percentage of all the queues
  on the left are high, the operation may be the bottleneck.

To optimize the performance of data processing operations, there are some
suggestions:

- If the Dataset Loading Operation is the bottleneck, try to increase the
  ``num_parallel_workers``.
- If the GeneratorOp Operation is the bottleneck, try to increase the
  ``num_parallel_workers`` or try to replace it with
  ``MindRecordDataset``.
- If the MapOp Operation is the bottleneck, try to increase the
  ``num_parallel_workers``. If it maps a Python operation, try to optimize
  the training script.
- If the BatchOp Operation is the bottleneck, try to adjust the size
  of ``prefetch_size``.

.. note::
   To obtain data to prepare performance data, using the module of MindSpore Dataset to define data process pipeline.