Preparing the Training Script
-----------------------------

There are two ways to collect neural network performance data. You can enable Profiler in either of the following ways.

Method 1: Modify the training script
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Add the MindSpore Profiler interface to the training script.

- Before training, initialize the MindSpore Profiler object, and profiler enables collection of performance data.

  .. note::
     The parameters of Profiler are as follows:
     `Profiler API <https://www.mindspore.cn/docs/en/master/api_python/mindspore/mindspore.Profiler.html#mindspore.Profiler>`_ .
     Before initializing the Profiler, you need to determine the device_id.

- At the end of the training, ``Profiler.analyse()`` should be called to finish profiling and generate the perforamnce analyse results.

** Unconditional Open example: **

- Example 1: In the MindSpore functional Programming use case, Profiler is used to collect performance data. Part of the sample code is shown below.
  `Complete code sample <https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_sample.py>`_ .

  .. code:: python

     # Init Profiler.
     # Note that the Profiler should be initialized before model training.
     profiler = Profiler(output_path="profiler_data")

     def forward_fn(data, label):
         logits = model(data)
         loss = loss_fn(logits, label)
         return loss, logits


     # Get gradient function
     grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)


     @ms.jit
     def train_step(data, label):
         """Define function of one-step training"""
         (loss, _), grads = grad_fn(data, label)
         loss = ops.depend(loss, optimizer(grads))
         return loss


     for t in range(epochs):
         train_loop(model, train_dataset, loss_fn, optimizer)

     profiler.analyse()

  .. note::
     The default mode of MindSpore is PyNative. If functional programming network is used to collect the performance data of Profiler static graph mode,
     mindspore.set_context(mode=mindspore.GRAPH_MODE) should be set into static graph mode.

- Example 2: model.train is used for network training. The complete code is as follows:

  .. code:: python

     import numpy as np
     from mindspore import nn
     import mindspore as ms
     import mindspore.dataset as ds

     class Net(nn.Cell):
         def __init__(self):
             super(Net, self).__init__()
             self.fc = nn.Dense(2, 2)

         def construct(self, x):
             return self.fc(x)


     def generator():
         for i in range(2):
             yield (np.ones([2, 2]).astype(np.float32), np.ones([2]).astype(np.int32))


     def train(net):
         optimizer = nn.Momentum(net.trainable_params(), 1, 0.9)
         loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)
         data = ds.GeneratorDataset(generator, ["data", "label"])
         model = ms.Model(net, loss, optimizer)
         model.train(1, data)


     if __name__ == '__main__':
         ms.set_context(mode=ms.GRAPH_MODE, device_target="Ascend")

         # Init Profiler
         # Note that the Profiler should be initialized before model.train
         profiler = ms.Profiler(output_path='./profiler_data')

         # Train Model
         net = Net()
         train(net)

         # Profiler end
         profiler.analyse()

** Conditional open example: **

The user decides not to start the Profiler by setting the initialization parameter start_profile to False, then starts the Profiler at the right time by calling Start, stops collecting data, and finally calls analyse to phase the data.
You can open and close the Profiler based on the epoch or step, and the data within the specified step or epoch interval is collected. There are two ways to collect performance data based on step or epoch, one is through user-defined training,
the other is through Callback based on step or epoch to open and close Profiler.

- Custom training:

  The MindSpore functional programming use case uses profilers for custom training by turning Profiler performance data on or off during a specified step interval or epoch interval. `Enable Profiler's complete code sample based on step <https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_step.py>`_.

  .. code:: python

     profiler = ms.Profiler(start_profile=False)
     data_loader = ds.create_dict_iterator()

     for i, data in enumerate(data_loader):
         train()
         if i==100:
             profiler.start()
         if i==200:
             profiler.stop()

     profiler.analyse()

- User-defined Callback

  - For data non-sink mode, there is only an opportunity to turn on and off CANN at the end of each step, so whether the CANN is turned on or off is based on the step. A custom Callback opens the Profiler's `complete code sample based on step <https://gitee.com/mindspore/docs/blob/master/docs/sample_code/mindinsight/profiler/profiling_feed_step.py>`_ .

    .. code:: python

       import mindspore as ms

       class StopAtStep(ms.Callback):
           def __init__(self, start_step, stop_step):
               super(StopAtStep, self).__init__()
               self.start_step = start_step
               self.stop_step = stop_step
               self.profiler = ms.Profiler(start_profile=False)

           def step_begin(self, run_context):
               cb_params = run_context.original_args()
               step_num = cb_params.cur_step_num
               if step_num == self.start_step:
                   self.profiler.start()

           def step_end(self, run_context):
               cb_params = run_context.original_args()
               step_num = cb_params.cur_step_num
               if step_num == self.stop_step:
                   self.profiler.stop()

           def end(self, run_context):
               self.profiler.analyse()

- For data sink mode, CANN is told to start and stop only after the end of each epoch, so it needs to start and stop based on the epoch. The Profiler sample code modification training script can be opened based on step according to a custom Callback.

  .. code:: python

     class StopAtEpoch(ms.Callback):
         def __init__(self, start_epoch, stop_epoch):
             super(StopAtEpoch, self).__init__()
             self.start_epoch = start_epoch
             self.stop_epoch = stop_epoch
             self.profiler = ms.Profiler(start_profile=False)

         def epoch_begin(self, run_context):
             cb_params = run_context.original_args()
             epoch_num = cb_params.cur_epoch_num
             if epoch_num == self.start_epoch:
                 self.profiler.start()

         def epoch_end(self, run_context):
             cb_params = run_context.original_args()
             epoch_num = cb_params.cur_epoch_num
             if epoch_num == self.stop_epoch:
                 self.profiler.stop()

         def end(self, run_context):
             self.profiler.analyse()

Method 2: Enable environment variables
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Before running the network script, configure Profiler configuration items.

.. code-block:: shell

   export MS_PROFILER_OPTIONS='{"start": true, "output_path": "/XXX", "memory": false, "hccl": false, "aicore_metrics": 0, "l2_cache": false}'

- `start` (bool, mandatory) - Set to true to enable Profiler. Set to false to disable performance data collection. Default value: false.

- `output_path` (str, optional) - Represents the path (absolute path) of the output data. Default valueï¼š "./data".

- `op_time` (bool, optional) - Indicates whether to collect operators performance data. Default values: true.

- `profile_memory` (bool, optional) - Tensor data will be collected. This data is collected when the value is true. When using this parameter, op_time must be set to true. Default value: false.

- `profile_communication` (bool, optional) - Indicates whether to collect communication performance data in multi-device training. This data is collected when the value is true. In single-device training, this parameter is not set correctly. When using this parameter, op_time must be set to true. Default value: false.

- `aicore_metrics` (int, optional) - Set the indicator type of AI Core. Default value: 0.

- `l2_cache` (bool, optional) - Set whether to collect l2 cache data. Default value: false.

- `timeline_limit` (int, optional) - Set the maximum storage size of the timeline file (unit M). When using this parameter, op_time must be set to true. Default value: 500.

- `data_process` (bool, optional) - Indicates whether to collect data to prepare performance data. Default value: true.

- `parallel_strategy` (bool, optional) - Indicates whether to collect parallel policy performance data. Default value: true.
