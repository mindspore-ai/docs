# 推理

<a href="https://gitee.com/mindspore/docs/blob/r1.2/docs/programming_guide/source_zh_cn/infer.md" target="_blank"><img src="./_static/logo_source.png"></a>

基于MindSpore训练后的模型，支持在Ascend 910 AI处理器、Ascend 310 AI处理器、GPU、CPU、端侧等多种不同的平台上执行推理。使用方法可参考如下教程：

- [在Ascend 910 AI处理器上执行推理](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/multi_platform_inference_ascend_910.html)
- [在Ascend 310 AI处理器上执行推理](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/multi_platform_inference_ascend_310.html)
- [在GPU上执行推理](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/multi_platform_inference_gpu.html)
- [在CPU上执行推理](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/multi_platform_inference_cpu.html)
- [在端侧执行推理](https://www.mindspore.cn/tutorial/lite/zh-CN/r1.2/quick_start/quick_start.html)

同时，MindSpore提供了一个轻量级、高性能的服务模块，称为MindSpore Serving，可帮助MindSpore开发者在生产环境中高效部署在线推理服务。使用方法可参考如下教程：

- [部署推理服务](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/serving_example.html)
- [基于MindSpore Serving部署分布式推理服务](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/serving_distributed_example.html)
- [基于gRPC接口访问MindSpore Serving服务](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/serving_grpc.html)
- [基于RESTful接口访问MindSpore Serving服务](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/serving_restful.html)
- [通过配置模型提供Servable](https://www.mindspore.cn/tutorial/inference/zh-CN/r1.2/serving_model.html)
