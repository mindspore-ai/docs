# MindSpore Reinforcement Release Notes

## Reinforcement 0.6.0-alpha Release Notes

### Major Features and Improvements

- [BETA] Support GAIL(Generative Adversarial Imitation Learning [Jonathan Ho et al..2016](https://proceedings.neurips.cc/paper/2016/file/cc7e2b878868cbae992d1fb743995d8f-Paper.pdf)) Algorithm. The algorithms are tuned on HalfCheetah environment and support GPU backends.
- [BETA] Support C51([Marc G. Bellemare et al..2017](https://arxiv.org/abs/1707.06887)) Algorithm. The algorithms are tuned on CartPole environment and support CPU backends.
- [BETA] Support CQL(Conservative Q-Learning [Aviral Kumar et al..2019](https://arxiv.org/pdf/1906.00949)) Algorithm. The algorithms are tuned on Hopper environment and support CPU and GPU backends.
- [BETA] Support AWAC(Accelerating Online Reinforcement Learning with Offline Datasets [Ashvin Nair et al..2020](https://arxiv.org/abs/2006.09359)) Algorithm. The algorithms are tuned on Ant environment and support CPU and GPU backends.
- [BETA] Support Dreamer([Danijar Hafner et al..2020](https://arxiv.org/abs/1912.01603)) Algorithm. The algorithms are tuned on Walker-walk environment and support GPU backends.

### Contributors

Thanks goes to these wonderful people:

Pro. Peter, Huanzhou Zhu, Bo Zhao, Gang Chen, Weifeng Chen, Liang Shi, Yijie Chen.
