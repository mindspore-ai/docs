{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6392a05",
   "metadata": {},
   "source": [
    "[![Download Notebook](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_notebook_en.svg)](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/master/tutorials/en/advanced/dataset/mindspore_record.ipynb)&emsp;[![View Source On Gitee](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.svg)](https://gitee.com/mindspore/docs/blob/master/tutorials/source_en/advanced/dataset/record.ipynb)\n",
    "\n",
    "# Converting Dataset to MindRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc6b7a",
   "metadata": {},
   "source": [
    "In MindSpore, the dataset used to train the network model can be converted into MindSpore-specific format data (MindSpore Record format), making it easier to save and load data. The goal is to normalize the user's dataset and further enable the reading of the data through the MindDataset interface and use it during the training process.\n",
    "\n",
    "![conversion](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/source_en/advanced/dataset/images/data_conversion_concept.png)\n",
    "\n",
    "In addition, the performance of MindSpore in some scenarios is optimized, and using the MindSpore Record data format can reduce disk IO and network IO overhead, which results in a better user experience.\n",
    "\n",
    "The MindSpore data format has the following features:\n",
    "\n",
    "1. Unified storage and access of user data are implemented, simplifying training data loading.\n",
    "2. Data is aggregated for storage, which can be efficiently read, managed and moved.\n",
    "3. Data encoding and decoding are efficient and transparent to users.\n",
    "4. The partition size is flexibly controlled to implement distributed training.\n",
    "\n",
    "## Record File Structure\n",
    "\n",
    "As shown in the following figure, a MindSpore Record file consists of a data file and an index file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c420641",
   "metadata": {},
   "source": [
    "![mindrecord](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/source_en/advanced/dataset/images/mindrecord.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61d5ed",
   "metadata": {},
   "source": [
    "The data file contains file headers, scalar data pages, and block data pages, which are used to store the training data after user normalization, and a single MindSpore Record file is recommended to be less than 20G, and the user can store the large dataset as multiple MindSpore Record files.\n",
    "\n",
    "The index file contains index information generated based on scalar data (such as image Label, image file name) for convenient retrieval and statistical dataset information.\n",
    "\n",
    "The specific purposes of file headers, scalar data pages, and block data pages in data files are as follows:\n",
    "\n",
    "- **File header**: the meta information of MindSpore Record file, which is mainly used to store file header size, scalar data page size, block data page size, Schema information, index field, statistics, file segment information, the correspondence between scalar data and block data, etc.\n",
    "\n",
    "- **Scalar data page**: mainly used to store integer, string, floating-point data, such as the Label of the image, the file name of the image, the length and width of the image, that is, the information suitable for storing with scalars will be saved here.\n",
    "\n",
    "- **Block data page**: mainly used to store binary strings, NumPy arrays and other data, such as binary image files themselves, dictionaries converted into text, etc.\n",
    "\n",
    "> It should be noted that neither the data files nor the index files can support renaming operations at this time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e41d89",
   "metadata": {},
   "source": [
    "## Converting Dataset to Record Format\n",
    "\n",
    "The following mainly describes how to convert CV class data and NLP class data to MindSpore Record file format, and read MindSpore Record file through the `MindDataset` interface.\n",
    "\n",
    "### Converting CV Class Dataset\n",
    "\n",
    "This example mainly uses a CV dataset containing 100 records and converts it to MindSpore Record format as an example, and describes how to convert a CV class dataset to the MindSpore Record file format and read it through the `MindDataset` interface.\n",
    "\n",
    "First, you need to create a dataset of 100 pictures and save it, whose sample contains three fields: `file_name` (string), `label` (integer), and `data` (binary), and then use the `MindDataset` interface to read the MindSpore Record file.\n",
    "\n",
    "1. Generate 100 images and convert them to MindSpore Record file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "940722c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from mindspore.mindrecord import FileWriter\n",
    "\n",
    "file_name = \"test_vision.mindrecord\"\n",
    "# Define the contained fields\n",
    "cv_schema = {\"file_name\": {\"type\": \"string\"},\n",
    "             \"label\": {\"type\": \"int32\"},\n",
    "             \"data\": {\"type\": \"bytes\"}}\n",
    "\n",
    "# Declare the MindSpore Record file format\n",
    "writer = FileWriter(file_name, shard_num=1, overwrite=True)\n",
    "writer.add_schema(cv_schema, \"it is a cv dataset\")\n",
    "writer.add_index([\"file_name\", \"label\"])\n",
    "\n",
    "# Building a dataset\n",
    "data = []\n",
    "for i in range(100):\n",
    "    sample = {}\n",
    "    white_io = BytesIO()\n",
    "    Image.new('RGB', ((i+1)*10, (i+1)*10), (255, 255, 255)).save(white_io, 'JPEG')\n",
    "    image_bytes = white_io.getvalue()\n",
    "    sample['file_name'] = str(i+1) + \".jpg\"\n",
    "    sample['label'] = i+1\n",
    "    sample['data'] = white_io.getvalue()\n",
    "\n",
    "    data.append(sample)\n",
    "    if i % 10 == 0:\n",
    "        writer.write_raw_data(data)\n",
    "        data = []\n",
    "\n",
    "if data:\n",
    "    writer.write_raw_data(data)\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6cabe8",
   "metadata": {},
   "source": [
    "If there is no error reported, the dataset conversion was successful.\n",
    "\n",
    "2. Read the MindSpore Record file format via the `MindDataset` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e33e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 100 samples\n"
     ]
    }
   ],
   "source": [
    "from mindspore.dataset import MindDataset\n",
    "from mindspore.dataset.vision import Decode\n",
    "\n",
    "# Read the MindSpore Record file format\n",
    "data_set = MindDataset(dataset_files=file_name)\n",
    "decode_op = Decode()\n",
    "data_set = data_set.map(operations=decode_op, input_columns=[\"data\"], num_parallel_workers=2)\n",
    "\n",
    "# Count the number of samples\n",
    "print(\"Got {} samples\".format(data_set.get_dataset_size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd383be2",
   "metadata": {},
   "source": [
    "### Converting NLP Class Dataset\n",
    "\n",
    "This example first creates a MindSpore Record file format with 100 records. Its sample contains eight fields, all of which are integer arrays, and then uses the `MindDataset` interface to read the MindSpore Record file.\n",
    "\n",
    "> For ease of presentation, the preprocessing process of converting text to lexicographic order is omitted here.\n",
    "\n",
    "1. Generate 100 images and convert them to MindSpore Record file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b433aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "\n",
    "# The full path of the output MindSpore Record file\n",
    "file_name = \"test_text.mindrecord\"\n",
    "\n",
    "# Defines the fields that the sample data contains\n",
    "nlp_schema = {\"source_sos_ids\": {\"type\": \"int64\", \"shape\": [-1]},\n",
    "              \"source_sos_mask\": {\"type\": \"int64\", \"shape\": [-1]},\n",
    "              \"source_eos_ids\": {\"type\": \"int64\", \"shape\": [-1]},\n",
    "              \"source_eos_mask\": {\"type\": \"int64\", \"shape\": [-1]},\n",
    "              \"target_sos_ids\": {\"type\": \"int64\", \"shape\": [-1]},\n",
    "              \"target_sos_mask\": {\"type\": \"int64\", \"shape\": [-1]},\n",
    "              \"target_eos_ids\": {\"type\": \"int64\", \"shape\": [-1]},\n",
    "              \"target_eos_mask\": {\"type\": \"int64\", \"shape\": [-1]}}\n",
    "\n",
    "# Declare the MindSpore Record file format\n",
    "writer = FileWriter(file_name, shard_num=1, overwrite=True)\n",
    "writer.add_schema(nlp_schema, \"Preprocessed nlp dataset.\")\n",
    "\n",
    "# Build a virtual dataset\n",
    "data = []\n",
    "for i in range(100):\n",
    "    sample = {\"source_sos_ids\": np.array([i, i + 1, i + 2, i + 3, i + 4], dtype=np.int64),\n",
    "              \"source_sos_mask\": np.array([i * 1, i * 2, i * 3, i * 4, i * 5, i * 6, i * 7], dtype=np.int64),\n",
    "              \"source_eos_ids\": np.array([i + 5, i + 6, i + 7, i + 8, i + 9, i + 10], dtype=np.int64),\n",
    "              \"source_eos_mask\": np.array([19, 20, 21, 22, 23, 24, 25, 26, 27], dtype=np.int64),\n",
    "              \"target_sos_ids\": np.array([28, 29, 30, 31, 32], dtype=np.int64),\n",
    "              \"target_sos_mask\": np.array([33, 34, 35, 36, 37, 38], dtype=np.int64),\n",
    "              \"target_eos_ids\": np.array([39, 40, 41, 42, 43, 44, 45, 46, 47], dtype=np.int64),\n",
    "              \"target_eos_mask\": np.array([48, 49, 50, 51], dtype=np.int64)}\n",
    "    data.append(sample)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        writer.write_raw_data(data)\n",
    "        data = []\n",
    "\n",
    "if data:\n",
    "    writer.write_raw_data(data)\n",
    "\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b687ab",
   "metadata": {},
   "source": [
    "2. Read the MindSpore Record format file through the MindDataset interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8079d993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 100 samples\n",
      "source_sos_ids: [0 1 2 3 4]\n",
      "source_sos_ids: [1 2 3 4 5]\n",
      "source_sos_ids: [2 3 4 5 6]\n",
      "source_sos_ids: [3 4 5 6 7]\n",
      "source_sos_ids: [4 5 6 7 8]\n",
      "source_sos_ids: [5 6 7 8 9]\n",
      "source_sos_ids: [ 6  7  8  9 10]\n",
      "source_sos_ids: [ 7  8  9 10 11]\n",
      "source_sos_ids: [ 8  9 10 11 12]\n",
      "source_sos_ids: [ 9 10 11 12 13]\n"
     ]
    }
   ],
   "source": [
    "from mindspore.dataset import MindDataset\n",
    "\n",
    "# Read MindSpore Record file format\n",
    "data_set = MindDataset(dataset_files=file_name, shuffle=False)\n",
    "\n",
    "# Count the number of samples\n",
    "print(\"Got {} samples\".format(data_set.get_dataset_size()))\n",
    "\n",
    "# Print the part of data\n",
    "count = 0\n",
    "for item in data_set.create_dict_iterator(output_numpy=True):\n",
    "    print(\"source_sos_ids:\", item[\"source_sos_ids\"])\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87b498",
   "metadata": {},
   "source": [
    "## Dumping Dataset to MindRecord\n",
    "\n",
    "MindSpore provides a tool class for converting commonly used datasets, capable of converting commonly used datasets to the MindSpore Record file format.\n",
    "\n",
    "> For more detailed descriptions of dataset transformations, refer to [API Documentation](https://www.mindspore.cn/docs/en/master/api_python/mindspore.mindrecord.html).\n",
    "\n",
    "### Dumping the CIFAR-10 Dataset\n",
    "\n",
    "Users can convert CIFAR-10 raw data to MindSpore Record and read it using the `MindDataset` interface via the `Dataset.save` class.\n",
    "\n",
    "1. Download the [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz) and use `Cifar10Dataset` to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b7e3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz (162.2 MB)\n",
      "\n",
      "file_sizes: 100%|████████████████████████████| 170M/170M [00:18<00:00, 9.34MB/s]\n",
      "Extracting tar.gz file...\n",
      "Successfully downloaded / unzipped to ./\n"
     ]
    }
   ],
   "source": [
    "from download import download\n",
    "from mindspore.dataset import Cifar10Dataset\n",
    "\n",
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/cifar-10-binary.tar.gz\"\n",
    "\n",
    "path = download(url, \"./\", kind=\"tar.gz\", replace=True)\n",
    "dataset = Cifar10Dataset(\"./cifar-10-batches-bin/\")  # load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2d837",
   "metadata": {},
   "source": [
    "2. Call the `Dataset.save` interface to dump the CIFAR-10 dataset into the MindSpore Record file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8cb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save(\"cifar10.mindrecord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8bda63",
   "metadata": {},
   "source": [
    "3. Read the MindSpore Record file format through the `MindDataset` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 60000 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mindspore.dataset import MindDataset\n",
    "\n",
    "# Read MindSpore Record file format\n",
    "data_set = MindDataset(dataset_files=\"cifar10.mindrecord\")\n",
    "\n",
    "# Count the number of samples\n",
    "print(\"Got {} samples\".format(data_set.get_dataset_size()))\n",
    "\n",
    "if os.path.exists(\"cifar10.mindrecord\") and os.path.exists(\"cifar10.mindrecord.db\"):\n",
    "    os.remove(\"cifar10.mindrecord\")\n",
    "    os.remove(\"cifar10.mindrecord.db\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

