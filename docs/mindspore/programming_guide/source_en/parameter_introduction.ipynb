{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python375",
   "display_name": "Python 3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Parameter\r\n",
    "\r\n",
    "`Ascend` `GPU` `CPU` `Beginner`\r\n",
    "\r\n",
    "[![](https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_source_en.png)](https://gitee.com/mindspore/docs/blob/r1.5/docs/mindspore/programming_guide/source_en/parameter_introduction.ipynb)&emsp;[![](https://gitee.com/mindspore/docs/raw/r1.5/resource/_static/logo_notebook_en.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/r1.5/programming_guide/zh_cn/mindspore_parameter_introduction.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Parameter` is a variable tensor, indicating the parameters that need to be updated during network training. Typically, it consists of `weight` and `bias`. \n",
    "\n",
    "For example, the `weight` and `bias` for `nn.Conv2d` is a tensor with the shape of `[out_channel, in_channel, kernel_size, kernel_size]` and a scalar with the shape of `[out_channel]`, respectively. For `nn.Dense`, the shapes are `[out_channel, in_channel]` and `[out_channel]`.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "from mindspore import nn\n",
    "\n",
    "conv_net = nn.Conv2d(in_channels=120, out_channels=240, kernel_size=4, has_bias=True, weight_init='normal')\n",
    "dense_net = nn.Dense(in_channels=3, out_channels=4, weight_init='normal', bias_init='zeros', has_bias=True)\n",
    "\n",
    "print(\"conv_net, weight shape:\", conv_net.weight.shape, \", bias shape:\", conv_net.bias.shape)\n",
    "print(\"dense_net, weight_shapeï¼š\", dense_net.weight.shape, \", bias shape:\", dense_net.bias.shape)\n",
    "```\n",
    "\n",
    "```python\n",
    "conv_net, weight shape: (240, 120, 4, 4) , bias shape:  (240,)\n",
    "dense_net, weight_shape: (4, 3) , bias shape:  (4,)\n",
    "```\n",
    "\n",
    "Usually, weight and bias are integrated in a `nn` operator, users can specify a kind of initialization method to initialize these parameters.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "During training, the optimizer will continually update the parameters according to the backward propagating gradients. The optimal parameters will be finally saved for evaluation usage.\n",
    "\n",
    "`Parameter` does not support sparse Tensor, such as [mindspore.RowTensor](https://www.mindspore.cn/docs/api/en/r1.5/api_python/mindspore/mindspore.RowTensor.html) and [mindspore.SparseTensor](https://www.mindspore.cn/docs/api/en/r1.5/api_python/mindspore/mindspore.SparseTensor.html). More information about `Parameter` initializing and updating can refer to [Parameter initialize](https://www.mindspore.cn/docs/programming_guide/en/r1.5/initializer.html) and [Parameter update](https://www.mindspore.cn/docs/programming_guide/en/r1.5/parameter.html).\n"
   ],
   "metadata": {}
  }
 ]
}