Using Offline Model for Inference
=================================

.. toctree::
  :maxdepth: 1

  multi_platform_inference_ascend_910
  multi_platform_inference_ascend_310
  multi_platform_inference_gpu
  multi_platform_inference_cpu
  apply_post_training_quantization