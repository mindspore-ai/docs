# mindspore.mint API接口变更

与上一版本2.4.10相比，MindSpore中`mindspore.mint`API接口的添加、删除和支持平台的更改信息如下表所示。

|API|变更状态|概述|支持平台|类别
|:----|:----|:----|:----|:----
[mindspore.mint.addbmm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.addbmm.html#mindspore.mint.addbmm)|New|对 batch1 和 batch2 应用批量矩阵乘法后进行规约加， input 和最终的结果相加。|r2.5.0: Ascend|BLAS和LAPACK运算
[mindspore.mint.addmm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.addmm.html#mindspore.mint.addmm)|New|对输入的两个二维矩阵mat1与mat2相乘，并将结果与input相加。|r2.5.0: Ascend|BLAS和LAPACK运算
[mindspore.mint.dot](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.dot.html#mindspore.mint.dot)|New|计算两个1DTensor的点积。|r2.5.0: Ascend|BLAS和LAPACK运算
[mindspore.mint.meshgrid](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.meshgrid.html#mindspore.mint.meshgrid)|New|从给定的Tensor生成网格矩阵。|r2.5.0: Ascend|BLAS和LAPACK运算
[mindspore.mint.mm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.mm.html#mindspore.mint.mm)|New|计算两个矩阵的乘积。|r2.5.0: Ascend|BLAS和LAPACK运算
[mindspore.mint.outer](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.outer.html#mindspore.mint.outer)|New|计算 input 和 vec2 的外积。|r2.5.0: Ascend|BLAS和LAPACK运算
[mindspore.mint.nn.functional.dropout2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.dropout2d.html#mindspore.mint.nn.functional.dropout2d)|New|在训练期间，以服从伯努利分布的概率 p 随机将输入Tensor的某些通道归零（对于形状为 $NCHW$ 的四维Tensor，其通道特征图指的是后两维 $HW$ 形状的二维特征图）。|r2.5.0: Ascend|Dropout函数
[mindspore.mint.nn.Dropout2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.Dropout2d.html#mindspore.mint.nn.Dropout2d)|New|在训练期间，以服从伯努利分布的概率 p 随机将输入Tensor的某些通道归零（对于shape为 $NCHW$ 的四维Tensor，其通道特征图指的是后两维 $HW$ 的二维特征图）。|r2.5.0: Ascend|Dropout层
[mindspore.mint.amax](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.amax.html#mindspore.mint.amax)|New|计算输入 input 中指定 dim 维度上所有元素的最大值，并根据 keepdim 参数决定是否保留该维度。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.amin](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.amin.html#mindspore.mint.amin)|New|计算输入 input 中指定 dim 维度上所有元素的最小值，并根据 keepdim 参数决定是否保留该维度。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.cumprod](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.cumprod.html#mindspore.mint.cumprod)|New|计算输入Tensor input 沿轴 dim 的累计积，当前为实验性接口。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.histc](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.histc.html#mindspore.mint.histc)|New|计算Tensor的直方图。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.logsumexp](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.logsumexp.html#mindspore.mint.logsumexp)|New|计算输入 input 中指定 dim 维度上所有元素指数和的对数（计算过程经过数值稳定处理）， 并根据 keepdim 参数决定是否保留该维度。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.norm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.norm.html#mindspore.mint.norm)|New|返回给定Tensor的矩阵范数或向量范数。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.std](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.std.html#mindspore.mint.std)|New|计算指定维度 dim 上的标准差。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.std_mean](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.std_mean.html#mindspore.mint.std_mean)|New|默认情况下，返回Tensor各维度上的标准差和均值。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.var](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.var.html#mindspore.mint.var)|New|计算指定维度 dim 上的方差。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.var_mean](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.var_mean.html#mindspore.mint.var_mean)|New|默认情况下，返回Tensor各维度上的方差和均值。|r2.5.0: Ascend|Reduction运算
[mindspore.mint.nn.functional.interpolate](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.interpolate.html#mindspore.mint.nn.functional.interpolate)|New|按照给定的 size 或 scale_factor 根据 mode 设置的插值方式，对输入 input 进行插值。|r2.5.0: Ascend|Vision函数
[mindspore.mint.distributed.P2POp](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.P2POp.html#mindspore.mint.distributed.P2POp)|New|用于存放关于'isend'、'irecv'相关的信息， 并用于 batch_isend_irecv 接口的入参。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.all_gather](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.all_gather.html#mindspore.mint.distributed.all_gather)|New|汇聚指定的通信组中的Tensor，并返回汇聚后的Tensor列表。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.all_gather_into_tensor](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.all_gather_into_tensor.html#mindspore.mint.distributed.all_gather_into_tensor)|New|汇聚指定的通信组中的Tensor，并返回汇聚后的张量。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.all_gather_object](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.all_gather_object.html#mindspore.mint.distributed.all_gather_object)|New|汇聚指定的通信组中的Python对象。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.all_reduce](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.all_reduce.html#mindspore.mint.distributed.all_reduce)|New|使用指定方式对通信组内的所有设备的Tensor数据进行规约操作，所有设备都得到相同的结果，返回规约操作后的张量。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.all_to_all](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.all_to_all.html#mindspore.mint.distributed.all_to_all)|New|根据用户输入的张量列表，将对应的张量发送到远端设备，并从其他设备接收张量，返回一个接收的张量列表。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.all_to_all_single](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.all_to_all_single.html#mindspore.mint.distributed.all_to_all_single)|New|根据用户输入的切分大小，把输入tensor切分后，发送到其他的设备上，并从其他设备接收切分块，然后合并到一个输出tensor中。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.barrier](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.barrier.html#mindspore.mint.distributed.barrier)|New|同步通信域内的多个进程。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.batch_isend_irecv](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.batch_isend_irecv.html#mindspore.mint.distributed.batch_isend_irecv)|New|异步地发送和接收张量。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.broadcast](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.broadcast.html#mindspore.mint.distributed.broadcast)|New|对输入数据整组广播。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.broadcast_object_list](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.broadcast_object_list.html#mindspore.mint.distributed.broadcast_object_list)|New|对输入Python对象进行整组广播。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.gather](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.gather.html#mindspore.mint.distributed.gather)|New|对通信组的输入张量进行聚合。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.gather_object](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.gather_object.html#mindspore.mint.distributed.gather_object)|New|对通信组的输入Python对象进行聚合。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.get_backend](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.get_backend.html#mindspore.mint.distributed.get_backend)|New|在指定通信组中获取当前分布式后端的名称。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.get_global_rank](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.get_global_rank.html#mindspore.mint.distributed.get_global_rank)|New|由指定通信组中的设备序号获取通信集群中的全局设备序号。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.get_group_rank](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.get_group_rank.html#mindspore.mint.distributed.get_group_rank)|New|由通信集群中的全局设备序号获取指定用户通信组中的rank ID。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.get_process_group_ranks](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.get_process_group_ranks.html#mindspore.mint.distributed.get_process_group_ranks)|New|获取指定通信组中的进程，并将通信组中的进程编号以列表方式返回。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.irecv](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.irecv.html#mindspore.mint.distributed.irecv)|New|异步接收张量到指定线程。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.isend](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.isend.html#mindspore.mint.distributed.isend)|New|异步发送张量到指定线程。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.new_group](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.new_group.html#mindspore.mint.distributed.new_group)|New|创建用户自定义的通信组实例。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.recv](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.recv.html#mindspore.mint.distributed.recv)|New|同步接收张量到指定线程。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.reduce](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.reduce.html#mindspore.mint.distributed.reduce)|New|规约指定通信组中的张量，并将规约结果发送到目标为dst的进程(全局的进程编号)中，返回发送到目标进程的张量。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.reduce_scatter](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.reduce_scatter.html#mindspore.mint.distributed.reduce_scatter)|New|规约并且分发指定通信组中的张量，返回分发后的张量。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.reduce_scatter_tensor](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.reduce_scatter_tensor.html#mindspore.mint.distributed.reduce_scatter_tensor)|New|规约并且分发指定通信组中的张量，返回分发后的张量。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.scatter](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.scatter.html#mindspore.mint.distributed.scatter)|New|对输入张量进行均匀散射到通信域的卡上。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.scatter_object_list](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.scatter_object_list.html#mindspore.mint.distributed.scatter_object_list)|New|对输入Python对象列表进行均匀散射到通信域的卡上。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.distributed.send](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.distributed.send.html#mindspore.mint.distributed.send)|New|同步发送张量到指定线程。|r2.5.0: Ascend|mindspore.mint.distributed
[mindspore.mint.optim.Adam](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.optim.Adam.html#mindspore.mint.optim.Adam)|New|Adaptive Moment Estimation (Adam)算法的实现。|r2.5.0: Ascend|mindspore.mint.optim
[mindspore.mint.cdist](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.cdist.html#mindspore.mint.cdist)|New|计算两个Tensor每对行向量之间的p-norm距离。|r2.5.0: Ascend|其他运算
[mindspore.mint.bernoulli](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.bernoulli.html#mindspore.mint.bernoulli)|New|从伯努利分布中进行采样，并根据输入 input 中第 i 个元素给出的概率值将输出 output 中的第 i 元素随机设置为0或1。|r2.5.0: Ascend|创建运算
[mindspore.mint.bincount](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.bincount.html#mindspore.mint.bincount)|New|统计 input 中每个值的出现次数。|r2.5.0: Ascend|创建运算
[mindspore.mint.clone](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.clone.html#mindspore.mint.clone)|New|返回一个输入Tensor的副本。|r2.5.0: Ascend|创建运算
[mindspore.mint.einsum](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.einsum.html#mindspore.mint.einsum)|New|基于爱因斯坦求和约定（Einsum）符号，沿着指定维度对输入Tensor元素的乘积求和。|r2.5.0: Ascend|创建运算
[mindspore.mint.empty](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.empty.html#mindspore.mint.empty)|New|创建一个数据没有初始化的Tensor。|r2.5.0: Ascend|创建运算
[mindspore.mint.empty_like](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.empty_like.html#mindspore.mint.empty_like)|New|创建一个未初始化的Tesnor，shape和 input 相同，dtype由 dtype 决定，Tensor使用的内存由 device 决定。|r2.5.0: Ascend|创建运算
[mindspore.mint.full_like](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.full_like.html#mindspore.mint.full_like)|New|返回一个shape与 input 相同并且使用 fill_value 填充的Tensor。|r2.5.0: Ascend|创建运算
[mindspore.mint.randint](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.randint.html#mindspore.mint.randint)|New|返回一个Tensor，shape和dtype由输入决定，其元素为 [ low , high ) 区间的随机整数。|r2.5.0: Ascend|创建运算
[mindspore.mint.randint_like](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.randint_like.html#mindspore.mint.randint_like)|New|返回一个Tensor，其元素为 [ low , high ) 区间的随机整数，根据 input 决定shape和dtype。|r2.5.0: Ascend|创建运算
[mindspore.mint.randn](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.randn.html#mindspore.mint.randn)|New|返回一个Tensor，shape和dtype由输入决定，其元素为服从标准正态分布的数字。|r2.5.0: Ascend|创建运算
[mindspore.mint.randn_like](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.randn_like.html#mindspore.mint.randn_like)|New|返回shape与输入相同，类型为 dtype 的Tensor，dtype由输入决定，其元素取值服从 $[0, 1)$ 区间内的正态分布。|r2.5.0: Ascend|创建运算
[mindspore.mint.randperm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.randperm.html#mindspore.mint.randperm)|New|生成从 0 到 n-1 的整数随机排列。|r2.5.0: Ascend|创建运算
[mindspore.mint.nn.functional.conv2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.conv2d.html#mindspore.mint.nn.functional.conv2d)|New|对输入Tensor计算二维卷积。|r2.5.0: Ascend|卷积函数
[mindspore.mint.nn.functional.conv3d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.conv3d.html#mindspore.mint.nn.functional.conv3d)|New|对输入Tensor计算三维卷积。|r2.5.0: Ascend|卷积函数
[mindspore.mint.nn.functional.conv_transpose2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.conv_transpose2d.html#mindspore.mint.nn.functional.conv_transpose2d)|New|将2D转置卷积运算应用于由多个输入平面组成的输入图像，有时也称为反卷积（尽管它不是实际的反卷积）。|r2.5.0: Ascend|卷积函数
[mindspore.mint.nn.Conv2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.Conv2d.html#mindspore.mint.nn.Conv2d)|New|二维卷积层。|r2.5.0: Ascend|卷积层
[mindspore.mint.nn.Conv3d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.Conv3d.html#mindspore.mint.nn.Conv3d)|New|三维卷积层。|r2.5.0: Ascend|卷积层
[mindspore.mint.nn.ConvTranspose2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ConvTranspose2d.html#mindspore.mint.nn.ConvTranspose2d)|New|将2D转置卷积运算应用于由多个输入平面组成的输入图像。|r2.5.0: Ascend|卷积层
[mindspore.mint.nn.Upsample](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.Upsample.html#mindspore.mint.nn.Upsample)|New|按照给定的 size 或 scale_factor 根据 mode 设置的插值方式，对输入 input 进行插值。|r2.5.0: Ascend|图像处理层
[mindspore.mint.nn.ConstantPad1d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ConstantPad1d.html#mindspore.mint.nn.ConstantPad1d)|New|根据参数 padding 以及 value 对输入 input 最后1维进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ConstantPad2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ConstantPad2d.html#mindspore.mint.nn.ConstantPad2d)|New|根据参数 padding 以及 value 对输入 input 最后2维进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ConstantPad3d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ConstantPad3d.html#mindspore.mint.nn.ConstantPad3d)|New|根据参数 padding 以及 value 对输入 input 最后3维进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ReflectionPad1d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ReflectionPad1d.html#mindspore.mint.nn.ReflectionPad1d)|New|使用输入边界的反射对输入最后1维 input 进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ReflectionPad2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ReflectionPad2d.html#mindspore.mint.nn.ReflectionPad2d)|New|使用输入边界的反射对输入最后2维 input 进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ReflectionPad3d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ReflectionPad3d.html#mindspore.mint.nn.ReflectionPad3d)|New|使用输入边界的反射对输入最后3维 input 进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ReplicationPad1d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ReplicationPad1d.html#mindspore.mint.nn.ReplicationPad1d)|New|使用输入边界值对输入最后1维 input 进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ReplicationPad2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ReplicationPad2d.html#mindspore.mint.nn.ReplicationPad2d)|New|使用输入边界值对输入最后2维 input 进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ReplicationPad3d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ReplicationPad3d.html#mindspore.mint.nn.ReplicationPad3d)|New|使用输入边界值对输入最后3维 input 进行填充。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ZeroPad1d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ZeroPad1d.html#mindspore.mint.nn.ZeroPad1d)|New|根据参数 padding 对输入 input 最后1维填充零。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ZeroPad2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ZeroPad2d.html#mindspore.mint.nn.ZeroPad2d)|New|根据参数 padding 对输入 input 最后2维填充零。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.ZeroPad3d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ZeroPad3d.html#mindspore.mint.nn.ZeroPad3d)|New|根据参数 padding 对输入 input 最后3维填充零。|r2.5.0: Ascend|填充层
[mindspore.mint.nn.Embedding](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.Embedding.html#mindspore.mint.nn.Embedding)|New|以 input 中的值作为索引，从 weight 中查询对应的embedding向量。|r2.5.0: Ascend|嵌入层
[mindspore.mint.nn.Identity](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.Identity.html#mindspore.mint.nn.Identity)|New|网络占位符，返回与输入完全一致。|r2.5.0: Ascend|工具
[mindspore.mint.nn.functional.normalize](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.normalize.html#mindspore.mint.nn.functional.normalize)|New|将输入的张量按照指定维度进行归一化。|r2.5.0: Ascend|归一化函数
[mindspore.mint.nn.BatchNorm1d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.BatchNorm1d.html#mindspore.mint.nn.BatchNorm1d)|New|在二维或三维输入上应用批归一化。|r2.5.0: Ascend|归一化层
[mindspore.mint.nn.BatchNorm2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.BatchNorm2d.html#mindspore.mint.nn.BatchNorm2d)|New|在四维输入上应用批归一化。|r2.5.0: Ascend|归一化层
[mindspore.mint.nn.BatchNorm3d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.BatchNorm3d.html#mindspore.mint.nn.BatchNorm3d)|New|在五维输入上应用批归一化。|r2.5.0: Ascend|归一化层
[mindspore.mint.nn.LayerNorm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.LayerNorm.html#mindspore.mint.nn.LayerNorm)|New|在mini-batch输入上应用层归一化（Layer Normalization）。|r2.5.0: Ascend|归一化层
[mindspore.mint.nn.SyncBatchNorm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.SyncBatchNorm.html#mindspore.mint.nn.SyncBatchNorm)|New|在N维输入上进行跨设备同步批归一化（Batch Normalization，BN）。|r2.5.0: Ascend|归一化层
[mindspore.mint.nn.BCELoss](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.BCELoss.html#mindspore.mint.nn.BCELoss)|New|计算目标值和预测值之间的二值交叉熵损失值。|r2.5.0: Ascend|损失函数
[mindspore.mint.nn.CrossEntropyLoss](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.CrossEntropyLoss.html#mindspore.mint.nn.CrossEntropyLoss)|New|获取预测值和目标值之间的交叉熵损失。|r2.5.0: Ascend|损失函数
[mindspore.mint.nn.NLLLoss](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.NLLLoss.html#mindspore.mint.nn.NLLLoss)|New|reduction为'none'时，负对数似然损失公式如下：。|r2.5.0: Ascend|损失函数
[mindspore.mint.nn.SmoothL1Loss](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.SmoothL1Loss.html#mindspore.mint.nn.SmoothL1Loss)|New|计算平滑L1损失，该L1损失函数有稳健性。|r2.5.0: Ascend|损失函数
[mindspore.mint.nn.functional.nll_loss](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.nll_loss.html#mindspore.mint.nn.functional.nll_loss)|New|获取预测值和目标值之间的负对数似然损失。|r2.5.0: Ascend|损失函数
[mindspore.mint.nn.functional.smooth_l1_loss](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.smooth_l1_loss.html#mindspore.mint.nn.functional.smooth_l1_loss)|New|计算平滑L1损失，该L1损失函数有稳健性。|r2.5.0: Ascend|损失函数
[mindspore.mint.allclose](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.allclose.html#mindspore.mint.allclose)|New|返回一个布尔型标量，表示 input 的每个元素均与 other 的对应元素在给定容忍度内“接近”。|r2.5.0: Ascend|比较运算
[mindspore.mint.argsort](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.argsort.html#mindspore.mint.argsort)|New|按指定顺序对输入Tensor沿给定维度进行排序，并返回排序后的索引。|r2.5.0: Ascend|比较运算
[mindspore.mint.equal](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.equal.html#mindspore.mint.equal)|New|比较两个输入是否相等。|r2.5.0: Ascend|比较运算
[mindspore.mint.isinf](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.isinf.html#mindspore.mint.isinf)|New|确定输入Tensor每个位置上的元素是否为正无穷或负无穷。|r2.5.0: Ascend|比较运算
[mindspore.mint.isneginf](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.isneginf.html#mindspore.mint.isneginf)|New|确定输入Tensor每个位置上的元素是否为负无穷。|r2.5.0: Ascend|比较运算
[mindspore.mint.not_equal](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.not_equal.html#mindspore.mint.not_equal)|New|mindspore.mint.ne() 的别名。|r2.5.0: Ascend|比较运算
[mindspore.mint.nn.functional.adaptive_avg_pool1d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.adaptive_avg_pool1d.html#mindspore.mint.nn.functional.adaptive_avg_pool1d)|New|对一个多平面输入信号执行一维自适应平均池化。|r2.5.0: Ascend|池化函数
[mindspore.mint.nn.functional.adaptive_avg_pool2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.adaptive_avg_pool2d.html#mindspore.mint.nn.functional.adaptive_avg_pool2d)|New|对一个多平面输入信号执行二维自适应平均池化。|r2.5.0: Ascend|池化函数
[mindspore.mint.nn.functional.avg_pool1d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.avg_pool1d.html#mindspore.mint.nn.functional.avg_pool1d)|New|在输入Tensor上应用1D平均池化，输入Tensor可以看作是由一系列1D平面组成的。|r2.5.0: Ascend|池化函数
[mindspore.mint.nn.functional.max_unpool2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.max_unpool2d.html#mindspore.mint.nn.functional.max_unpool2d)|New|max_pool2d 的逆过程。|r2.5.0: Ascend|池化函数
[mindspore.mint.nn.AdaptiveAvgPool1d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.AdaptiveAvgPool1d.html#mindspore.mint.nn.AdaptiveAvgPool1d)|New|对由多个输入平面组成的输入信号应用1D自适应平均池化。|r2.5.0: Ascend|池化层
[mindspore.mint.nn.AdaptiveAvgPool2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.AdaptiveAvgPool2d.html#mindspore.mint.nn.AdaptiveAvgPool2d)|New|对由多个输入平面组成的输入信号应用2D自适应平均池化。|r2.5.0: Ascend|池化层
[mindspore.mint.nn.AdaptiveAvgPool3d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.AdaptiveAvgPool3d.html#mindspore.mint.nn.AdaptiveAvgPool3d)|New|对输入Tensor，提供三维的自适应平均池化操作。|r2.5.0: Ascend|池化层
[mindspore.mint.nn.MaxUnpool2d](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.MaxUnpool2d.html#mindspore.mint.nn.MaxUnpool2d)|New|Maxpool2d 的逆过程。|r2.5.0: Ascend|池化层
[mindspore.mint.chunk](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.chunk.html#mindspore.mint.chunk)|New|沿着指定轴 dim 将输入Tensor切分成 chunks 个sub-tensor。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.concat](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.concat.html#mindspore.mint.concat)|New|mindspore.mint.cat() 的别名。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.count_nonzero](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.count_nonzero.html#mindspore.mint.count_nonzero)|New|计算输入Tensor指定轴上的非零元素的数量。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.reshape](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.reshape.html#mindspore.mint.reshape)|New|基于给定的 shape ，对输入Tensor进行重新排列。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.select](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.select.html#mindspore.mint.select)|New|在给定索引处沿选定维度对输入张量进行切片。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.squeeze](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.squeeze.html#mindspore.mint.squeeze)|New|返回删除指定 dim 中大小为1的维度后的Tensor。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.swapaxes](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.swapaxes.html#mindspore.mint.swapaxes)|New|mindspore.mint.transpose() 的别名。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.transpose](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.transpose.html#mindspore.mint.transpose)|New|交换Tensor的两个维度。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.triu](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.triu.html#mindspore.mint.triu)|New|返回输入Tensor input 的上三角形部分(包含对角线和下面的元素)，并将其他元素设置为0。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.unbind](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.unbind.html#mindspore.mint.unbind)|New|根据指定轴对Tensor进行分解。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.unique_consecutive](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.unique_consecutive.html#mindspore.mint.unique_consecutive)|New|对输入Tensor中连续且重复的元素去重。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.unsqueeze](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.unsqueeze.html#mindspore.mint.unsqueeze)|New|对输入 input 在给定维上添加额外维度。|r2.5.0: Ascend|索引、切分、连接、突变运算
[mindspore.mint.linalg.matrix_norm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.linalg.matrix_norm.html#mindspore.mint.linalg.matrix_norm)|New|返回给定Tensor在指定维度上的矩阵范数。|r2.5.0: Ascend|逆数
[mindspore.mint.linalg.norm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.linalg.norm.html#mindspore.mint.linalg.norm)|New|返回给定Tensor的矩阵范数或向量范数。|r2.5.0: Ascend|逆数
[mindspore.mint.linalg.vector_norm](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.linalg.vector_norm.html#mindspore.mint.linalg.vector_norm)|New|返回给定Tensor在指定维度上的向量范数。|r2.5.0: Ascend|逆数
[mindspore.mint.addmv](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.addmv.html#mindspore.mint.addmv)|New|mat 和 vec 矩阵向量相乘，且将输入向量 input 加到最终结果中。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.diff](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.diff.html#mindspore.mint.diff)|New|计算沿给定维度的第n个正向差。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.exp2](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.exp2.html#mindspore.mint.exp2)|New|逐元素计算Tensor input 以2为底的指数。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.float_power](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.float_power.html#mindspore.mint.float_power)|New|使用双精度计算 input 中每个元素的 exponent 次幂，并返回一个float64类型的Tensor。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.fmod](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.fmod.html#mindspore.mint.fmod)|New|计算除法运算 input/other 的浮点余数。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.frac](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.frac.html#mindspore.mint.frac)|New|计算 input 中每个元素的小数部分。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.lerp](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.lerp.html#mindspore.mint.lerp)|New|基于权重参数计算两个Tensor之间的线性插值。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.log10](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.log10.html#mindspore.mint.log10)|New|逐元素返回Tensor以10为底的对数。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.log2](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.log2.html#mindspore.mint.log2)|New|逐元素返回Tensor以2为底的对数。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.logaddexp](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.logaddexp.html#mindspore.mint.logaddexp)|New|计算输入的指数和的对数。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.mv](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.mv.html#mindspore.mint.mv)|New|实现矩阵 input 和向量 vec 相乘。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.nan_to_num](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nan_to_num.html#mindspore.mint.nan_to_num)|New|将 input 中的 NaN 、正无穷大和负无穷大值分别替换为 nan 、posinf 和 neginf 指定的值。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.nansum](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nansum.html#mindspore.mint.nansum)|New|计算 input 指定维度元素的和，将非数字(NaNs)处理为零。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.polar](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.polar.html#mindspore.mint.polar)|New|将极坐标转化为笛卡尔坐标。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.ravel](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.ravel.html#mindspore.mint.ravel)|New|沿着0轴方向，将多维Tensor展开成一维。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.softmax](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.softmax.html#mindspore.mint.softmax)|New|mindspore.mint.nn.functional.softmax() 的别名。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.special.exp2](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.special.exp2.html#mindspore.mint.special.exp2)|New|逐元素计算Tensor input 以2为底的指数。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.t](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.t.html#mindspore.mint.t)|New|转置输入Tensor。|r2.5.0: Ascend|逐元素运算
[mindspore.mint.multinomial](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.multinomial.html#mindspore.mint.multinomial)|New|根据输入生成一个多项式分布的Tensor。|r2.5.0: Ascend|随机采样
[mindspore.mint.nn.functional.logsigmoid](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.logsigmoid.html#mindspore.mint.nn.functional.logsigmoid)|New|按元素计算LogSigmoid激活函数。|r2.5.0: Ascend|非线性激活函数
[mindspore.mint.nn.functional.relu6](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.relu6.html#mindspore.mint.nn.functional.relu6)|New|逐元素计算输入Tensor的ReLU（修正线性单元），其上限为6。|r2.5.0: Ascend|非线性激活函数
[mindspore.mint.nn.functional.relu_](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.functional.relu_.html#mindspore.mint.nn.functional.relu_)|New|对输入Tensor逐元素原地计算线性修正单元激活函数（Rectified Linear Unit）值。|r2.5.0: Ascend|非线性激活函数
[mindspore.mint.nn.ELU](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ELU.html#mindspore.mint.nn.ELU)|New|指数线性单元激活函数(Exponential Linear Unit activation function)。|r2.5.0: Ascend|非线性激活层 (加权和，非线性)
[mindspore.mint.nn.LogSigmoid](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.LogSigmoid.html#mindspore.mint.nn.LogSigmoid)|New|逐元素计算LogSigmoid激活函数。|r2.5.0: Ascend|非线性激活层 (加权和，非线性)
[mindspore.mint.nn.ReLU6](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.ReLU6.html#mindspore.mint.nn.ReLU6)|New|ReLU6激活函数。|r2.5.0: Ascend|非线性激活层 (加权和，非线性)
[mindspore.mint.nn.SiLU](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.SiLU.html#mindspore.mint.nn.SiLU)|New|逐元素计算SiLU激活函数。|r2.5.0: Ascend|非线性激活层 (加权和，非线性)
[mindspore.mint.nn.Tanh](https://mindspore.cn/docs/zh-CN/r2.5.0/api_python/mint/mindspore.mint.nn.Tanh.html#mindspore.mint.nn.Tanh)|New|逐元素计算Tanh（双曲正切值）激活函数，返回一个新的Tensor。|r2.5.0: Ascend|非线性激活层 (加权和，非线性)

