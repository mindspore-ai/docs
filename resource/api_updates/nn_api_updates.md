# API Updates

Compared with the previous version, the added, deleted and supported platforms change information of `mindspore.nn` operators in MindSpore, is shown in the following table.

|API|Status|Description|Support Platform|Class
|:----|:----|:----|:----|:----
|[mindspore.nn.LossBase](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.LossBase.html#mindspore.nn.LossBase)|New|Base class for other losses.|r1.3: Ascend/GPU/CPU|Loss Functions
|[mindspore.nn.thor](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.thor.html#mindspore.nn.thor)|New|Updates gradients by second-order algorithmâ€“THOR.|r1.3: Ascend/GPU|Optimizer Functions
|[mindspore.nn.SparseTensorDenseMatmul](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.SparseTensorDenseMatmul.html#mindspore.nn.SparseTensorDenseMatmul)|New|Multiplies sparse matrix  a  and dense matrix  b .|r1.3: CPU|Sparse Layers
|[mindspore.nn.DenseThor](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.DenseThor.html#mindspore.nn.DenseThor)|New|The dense connected layer and saving the information needed for THOR.|r1.3: Ascend/GPU|Thor Layers
|[mindspore.nn.EmbeddingThor](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.EmbeddingThor.html#mindspore.nn.EmbeddingThor)|New|A simple lookup table that stores embeddings of a fixed dictionary and size and saving the information needed for THOR.|r1.3: Ascend/GPU|Thor Layers
|[mindspore.nn.Conv2dThor](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.Conv2dThor.html#mindspore.nn.Conv2dThor)|New|2D convolution layer and saving the information needed for THOR.|r1.3: Ascend/GPU|Thor Layers
|[mindspore.nn.PipelineCell](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.PipelineCell.html#mindspore.nn.PipelineCell)|New|Wrap the network with Micro Batch.|r1.3: To Be Developed|Wrapper Functions
|[mindspore.nn.GraphKernel](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.GraphKernel.html#mindspore.nn.GraphKernel)|Changed |Base class for GraphKernel.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Cell
|[mindspore.nn.SequentialCell](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.SequentialCell.html#mindspore.nn.SequentialCell)|Changed |Sequential cell container.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Containers
|[mindspore.nn.CellList](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.CellList.html#mindspore.nn.CellList)|Changed |Holds Cells in a list.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Containers
|[mindspore.nn.Conv1dTranspose](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.Conv1dTranspose.html#mindspore.nn.Conv1dTranspose)|Changed |1D transposed convolution layer.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Convolution Layers
|[mindspore.nn.Conv2dTranspose](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.Conv2dTranspose.html#mindspore.nn.Conv2dTranspose)|Changed |2D transposed convolution layer.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Convolution Layers
|[mindspore.nn.Conv3d](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.Conv3d.html#mindspore.nn.Conv3d)|Changed |3D convolution layer.|r1.2: Ascend => r1.3: Ascend/GPU|Convolution Layers
|[mindspore.nn.PSNR](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.PSNR.html#mindspore.nn.PSNR)|Changed |Returns Peak Signal-to-Noise Ratio of two image batches.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Images Functions
|[mindspore.nn.SSIM](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.SSIM.html#mindspore.nn.SSIM)|Changed |Returns SSIM index between two images.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Images Functions
|[mindspore.nn.FocalLoss](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.FocalLoss.html#mindspore.nn.FocalLoss)|Changed |The loss function proposed by Kaiming team in their paper  Focal Loss for Dense Object Detection  improves the effect of image object detection.|r1.2: Ascend/GPU => r1.3: Ascend|Loss Functions
|[mindspore.nn.Moments](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.Moments.html#mindspore.nn.Moments)|Changed |Calculates the mean and variance of  x .|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Math Functions
|[mindspore.nn.ReduceLogSumExp](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.ReduceLogSumExp.html#mindspore.nn.ReduceLogSumExp)|Changed |Reduces a dimension of a tensor by calculating exponential for all elements in the dimension, then calculate logarithm of the sum.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Math Functions
|[mindspore.nn.LogSoftmax](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.LogSoftmax.html#mindspore.nn.LogSoftmax)|Changed |LogSoftmax activation function.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Non-linear Activations
|[mindspore.nn.PReLU](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.PReLU.html#mindspore.nn.PReLU)|Changed |PReLU activation function.|r1.2: Ascend => r1.3: Ascend/GPU|Non-linear Activations
|[mindspore.nn.BatchNorm1d](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.BatchNorm1d.html#mindspore.nn.BatchNorm1d)|Changed |Batch Normalization layer over a 2D input.|r1.2: Ascend => r1.3: Ascend/GPU/CPU|Normalization Layers
|[mindspore.nn.AdamWeightDecay](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.AdamWeightDecay.html#mindspore.nn.AdamWeightDecay)|Changed |Implements the Adam algorithm to fix the weight decay.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Optimizer Functions
|[mindspore.nn.LARS](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.LARS.html#mindspore.nn.LARS)|Changed |Implements the LARS algorithm with LARSUpdate Operator.|r1.2: Ascend => r1.3: Ascend/CPU|Optimizer Functions
|[mindspore.nn.SGD](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.SGD.html#mindspore.nn.SGD)|Changed |Implements stochastic gradient descent.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Optimizer Functions
|[mindspore.nn.Embedding](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.Embedding.html#mindspore.nn.Embedding)|Changed |A simple lookup table that stores embeddings of a fixed dictionary and size.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Sparse Layers
|[mindspore.nn.WithLossCell](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.WithLossCell.html#mindspore.nn.WithLossCell)|Changed |Cell with loss function.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Wrapper Functions
|[mindspore.nn.TrainOneStepCell](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.TrainOneStepCell.html#mindspore.nn.TrainOneStepCell)|Changed |Network training package class.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Wrapper Functions
|[mindspore.nn.WithEvalCell](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.WithEvalCell.html#mindspore.nn.WithEvalCell)|Changed |Cell that returns loss, output and label for evaluation.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Wrapper Functions
|[mindspore.nn.WithGradCell](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.WithGradCell.html#mindspore.nn.WithGradCell)|Changed |Cell that returns the gradients.|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Wrapper Functions
|[mindspore.nn.BCEWithLogitsLoss](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.BCEWithLogitsLoss.html#mindspore.nn.BCEWithLogitsLoss)|Changed |Adds sigmoid activation function to input logits, and uses the given logits to compute binary cross entropy between the labels and the output. Ascend|r1.2: Ascend => r1.3: Ascend/GPU|Loss Functions
|[mindspore.nn.Adam](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.Adam.html#mindspore.nn.Adam)|Changed |Updates gradients by the Adaptive Moment Estimation (Adam) algorithm. Ascend|r1.2: Ascend/GPU => r1.3: Ascend/GPU/CPU|Optimizer Functions
|[mindspore.nn.DistributedGradReducer](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.DistributedGradReducer.html#mindspore.nn.DistributedGradReducer)|Changed |A distributed optimizer.|r1.2: , /GPU => r1.3: Ascend/GPU|Wrapper Functions
|[mindspore.nn.ParameterUpdate](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.ParameterUpdate.html#mindspore.nn.ParameterUpdate)|Changed |Cell that updates parameter.|r1.2: Ascend => r1.3: Ascend/GPU/CPU|Wrapper Functions
|[mindspore.nn.SparseToDense](https://www.mindspore.cn/docs/api/zh-CN/r1.3/api_python/nn/mindspore.nn.SparseToDense.html#mindspore.nn.SparseToDense)|Changed |Converts a sparse tensor into dense.|CPU|r1.2: Utilities => r1.3: Sparse Layers

>
