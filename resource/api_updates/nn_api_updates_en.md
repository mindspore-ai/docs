# mindspore.nn API Interface Change

Compared with the previous version, the added, deleted and supported platforms change information of `mindspore.nn` operators in MindSpore, is shown in the following table.

|API|Status|Description|Support Platform|Class
|:----|:----|:----|:----|:----
[mindspore.nn.CellDict](https://mindspore.cn/docs/en/r2.2/api_python/nn/mindspore.nn.CellDict.html#mindspore.nn.CellDict)|New|Holds Cells in a dictionary.|r2.2: Ascend/GPU/CPU|Container
[mindspore.nn.optim_ex.Adam](https://mindspore.cn/docs/en/r2.1/api_python/nn/mindspore.nn.optim_ex.Adam.html#mindspore.nn.optim_ex.Adam)|Changed|Implements Adam algorithm.|Ascend/GPU/CPU|r2.1: Experimental Optimizer => r2.2: [mindspore.experimental.optim.Adam](https://www.mindspore.cn/docs/en/r2.2/api_python/experimental/optim/mindspore.experimental.optim.Adam.html#mindspore.experimental.optim.Adam)
[mindspore.nn.optim_ex.AdamW](https://mindspore.cn/docs/en/r2.1/api_python/nn/mindspore.nn.optim_ex.AdamW.html#mindspore.nn.optim_ex.AdamW)|Changed|Implements Adam Weight Decay algorithm.|Ascend/GPU/CPU|r2.1: Experimental Optimizer => r2.2: [mindspore.experimental.optim.AdamW](https://www.mindspore.cn/docs/en/r2.2/api_python/experimental/optim/mindspore.experimental.optim.AdamW.html#mindspore.experimental.optim.AdamW)
[mindspore.nn.optim_ex.Optimizer](https://mindspore.cn/docs/en/r2.1/api_python/nn/mindspore.nn.optim_ex.Optimizer.html#mindspore.nn.optim_ex.Optimizer)|Changed|Base class for all optimizers.|Ascend/GPU/CPU|r2.1: Experimental Optimizer => r2.2: [mindspore.experimental.optim.Optimizer](https://www.mindspore.cn/docs/en/r2.2/api_python/experimental/optim/mindspore.experimental.optim.Optimizer.html#mindspore.experimental.optim.Optimizer)
[mindspore.nn.optim_ex.SGD](https://mindspore.cn/docs/en/r2.1/api_python/nn/mindspore.nn.optim_ex.SGD.html#mindspore.nn.optim_ex.SGD)|Changed|Stochastic Gradient Descent optimizer.|Ascend/GPU/CPU|r2.1: Experimental Optimizer => r2.2: [mindspore.experimental.optim.SGD](https://www.mindspore.cn/docs/en/r2.2/api_python/experimental/optim/mindspore.experimental.optim.SGD.html#mindspore.experimental.optim.SGD)
[mindspore.nn.LRScheduler](https://mindspore.cn/docs/en/r2.1/api_python/nn/mindspore.nn.LRScheduler.html#mindspore.nn.LRScheduler)|Changed|Basic class of learning rate schedule.|Ascend/GPU/CPU|r2.1: LRScheduler Class => r2.2: [mindspore.experimental.optim.lr_scheduler.LRScheduler](https://www.mindspore.cn/docs/en/r2.2/api_python/experimental/optim/mindspore.experimental.optim.lr_scheduler.LRScheduler.html#mindspore.experimental.optim.lr_scheduler.LRScheduler)
[mindspore.nn.LinearLR](https://mindspore.cn/docs/en/r2.1/api_python/nn/mindspore.nn.LinearLR.html#mindspore.nn.LinearLR)|Changed|Decays the learning rate of each parameter group by linearly changing small multiplicative factor until the number of epoch reaches a pre-defined milestone: total_iters.|Ascend/GPU/CPU|r2.1: LRScheduler Class => r2.2: [mindspore.experimental.optim.lr_scheduler.LinearLR](https://www.mindspore.cn/docs/en/r2.2/api_python/experimental/optim/mindspore.experimental.optim.lr_scheduler.LinearLR.html#mindspore.experimental.optim.lr_scheduler.LinearLR)
[mindspore.nn.StepLR](https://mindspore.cn/docs/en/r2.1/api_python/nn/mindspore.nn.StepLR.html#mindspore.nn.StepLR)|Changed|Decays the learning rate of each parameter group by gamma every step_size epochs.|Ascend/GPU/CPU|r2.1: LRScheduler Class => r2.2: [mindspore.experimental.optim.lr_scheduler.StepLR](https://www.mindspore.cn/docs/en/r2.2/api_python/experimental/optim/mindspore.experimental.optim.lr_scheduler.StepLR.html#mindspore.experimental.optim.lr_scheduler.StepLR)
[mindspore.nn.LRN](https://mindspore.cn/docs/en/r2.2/api_python/nn/mindspore.nn.LRN.html#mindspore.nn.LRN)|Changed|Local Response Normalization.|r2.1: Ascend/GPU/CPU => r2.2: GPU/CPU|Nonlinear Activation Layer
