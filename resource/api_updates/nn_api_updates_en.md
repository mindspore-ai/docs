# mindspore.nn API Interface Change

Compared with the previous version, the added, deleted and supported platforms change information of `mindspore.nn` operators in MindSpore, is shown in the following table.

|API|Status|Description|Support Platform|Class
|:----|:----|:----|:----|:----
[mindspore.nn.Dropout1d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Dropout1d.html#mindspore.nn.Dropout1d)|New|During training, randomly zeroes entire channels of the input tensor with probability p from a Bernoulli distribution (For a 3-dimensional tensor with a shape of $(N, C, L)$, the channel feature map refers to a 1-dimensional feature map with the shape of $L$).|r2.0: Ascend/GPU/CPU|Dropout Layer
[mindspore.nn.Accuracy](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Accuracy.html#mindspore.nn.Accuracy)|Deleted|Calculates the accuracy for classification and multilabel data.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.BleuScore](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.BleuScore.html#mindspore.nn.BleuScore)|Deleted|Calculates the BLEU score.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.ConfusionMatrix](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.ConfusionMatrix.html#mindspore.nn.ConfusionMatrix)|Deleted|Computes the confusion matrix, which is commonly used to evaluate the performance of classification models, including binary classification and multiple classification.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.ConfusionMatrixMetric](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.ConfusionMatrixMetric.html#mindspore.nn.ConfusionMatrixMetric)|Deleted|Computes metrics related to confusion matrix.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.CosineSimilarity](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.CosineSimilarity.html#mindspore.nn.CosineSimilarity)|Deleted|Computes representation similarity.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Dice](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Dice.html#mindspore.nn.Dice)|Deleted|The Dice coefficient is a set similarity metric.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.F1](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.F1.html#mindspore.nn.F1)|Deleted|Calculates the F1 score.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Fbeta](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Fbeta.html#mindspore.nn.Fbeta)|Deleted|Calculates the Fbeta score.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.HausdorffDistance](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.HausdorffDistance.html#mindspore.nn.HausdorffDistance)|Deleted|Calculates the Hausdorff distance.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Loss](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Loss.html#mindspore.nn.Loss)|Deleted|Calculates the average of the loss.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.MAE](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.MAE.html#mindspore.nn.MAE)|Deleted|Calculates the mean absolute error(MAE).|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.MSE](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.MSE.html#mindspore.nn.MSE)|Deleted|Measures the mean squared error(MSE).|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.MeanSurfaceDistance](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.MeanSurfaceDistance.html#mindspore.nn.MeanSurfaceDistance)|Deleted|Computes the Average Surface Distance from y_pred to y under the default setting.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Metric](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Metric.html#mindspore.nn.Metric)|Deleted|Base class of metric, which is used to evaluate metrics.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.OcclusionSensitivity](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.OcclusionSensitivity.html#mindspore.nn.OcclusionSensitivity)|Deleted|Calculates the occlusion sensitivity of the model for a given image, which illustrates which parts of an image are most important for a network’s classification.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Perplexity](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Perplexity.html#mindspore.nn.Perplexity)|Deleted|Computes perplexity.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Precision](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Precision.html#mindspore.nn.Precision)|Deleted|Calculates precision for classification and multilabel data.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.ROC](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.ROC.html#mindspore.nn.ROC)|Deleted|Calculates the ROC curve.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Recall](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Recall.html#mindspore.nn.Recall)|Deleted|Calculates recall for classification and multilabel data.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.RootMeanSquareDistance](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.RootMeanSquareDistance.html#mindspore.nn.RootMeanSquareDistance)|Deleted|Computes the Root Mean Square Surface Distance from y_pred to y under the default setting.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Top1CategoricalAccuracy](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Top1CategoricalAccuracy.html#mindspore.nn.Top1CategoricalAccuracy)|Deleted|Calculates the top-1 categorical accuracy.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.Top5CategoricalAccuracy](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Top5CategoricalAccuracy.html#mindspore.nn.Top5CategoricalAccuracy)|Deleted|Calculates the top-5 categorical accuracy.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.TopKCategoricalAccuracy](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.TopKCategoricalAccuracy.html#mindspore.nn.TopKCategoricalAccuracy)|Deleted|Calculates the top-k categorical accuracy.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.auc](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.auc.html#mindspore.nn.auc)|Deleted|Computes the AUC(Area Under the Curve) using the trapezoidal rule.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.get_metric_fn](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.get_metric_fn.html#mindspore.nn.get_metric_fn)|Deleted|Gets the metric method based on the input name.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.names](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.names.html#mindspore.nn.names)|Deleted|Gets all names of the metric methods.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.rearrange_inputs](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.rearrange_inputs.html#mindspore.nn.rearrange_inputs)|Deleted|This decorator is used to rearrange the inputs according to its indexes attribute of the class.|Ascend/GPU/CPU|Evaluation Metrics
[mindspore.nn.CentralCrop](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.CentralCrop.html#mindspore.nn.CentralCrop)|Deleted|Crops the central region of the images with the central_fraction.|Ascend/GPU/CPU|Image Processing Layer
[mindspore.nn.ImageGradients](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.ImageGradients.html#mindspore.nn.ImageGradients)|Deleted|Returns two tensors, the first is along the height dimension and the second is along the width dimension.|Ascend/GPU/CPU|Image Processing Layer
[mindspore.nn.MSSSIM](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.MSSSIM.html#mindspore.nn.MSSSIM)|Deleted|Returns MS-SSIM index between two images.|Ascend/GPU|Image Processing Layer
[mindspore.nn.PSNR](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.PSNR.html#mindspore.nn.PSNR)|Deleted|Returns Peak Signal-to-Noise Ratio of two image batches.|Ascend/GPU/CPU|Image Processing Layer
[mindspore.nn.PixelShuffle](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.PixelShuffle.html#mindspore.nn.PixelShuffle)|New|Applies the PixelShuffle operation over input which implements sub-pixel convolutions with stride $1/r$ .|r2.0: Ascend/GPU/CPU|Image Processing Layer
[mindspore.nn.PixelUnshuffle](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.PixelUnshuffle.html#mindspore.nn.PixelUnshuffle)|New|Applies the PixelUnshuffle operation over input which is the inverse of PixelShuffle.|r2.0: Ascend/GPU/CPU|Image Processing Layer
[mindspore.nn.ResizeBilinear](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ResizeBilinear.html#mindspore.nn.ResizeBilinear)|Changed|r1.10: Samples the input tensor to the given size or scale_factor by using bilinear interpolate. => r2.0: ‘nn.ResizeBilinear’ is deprecated from version 2.0 and will be removed in a future version, use mindspore.ops.ResizeBilinearV2 or mindspore.ops.interpolate() instead.|r1.10: Ascend/CPU/GPU => r2.0: |Image Processing Layer
[mindspore.nn.SSIM](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.SSIM.html#mindspore.nn.SSIM)|Deleted|Returns SSIM index between two images.|Ascend/GPU/CPU|Image Processing Layer
[mindspore.nn.Upsample](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Upsample.html#mindspore.nn.Upsample)|New|For details, please refer to mindspore.ops.interpolate().|r2.0: Ascend/GPU/CPU|Image Processing Layer
[mindspore.nn.WarmUpLR](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.WarmUpLR.html#mindspore.nn.WarmUpLR)|Changed|Gets learning rate warming up.|r1.10: Ascend/GPU => r2.0: Ascend/GPU/CPU|LearningRateSchedule Class
[mindspore.nn.CTCLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.CTCLoss.html#mindspore.nn.CTCLoss)|New|Calculates the CTC (Connectionist Temporal Classification) loss.|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.GaussianNLLLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.GaussianNLLLoss.html#mindspore.nn.GaussianNLLLoss)|New|Gaussian negative log likelihood loss.|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.HingeEmbeddingLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.HingeEmbeddingLoss.html#mindspore.nn.HingeEmbeddingLoss)|New|Calculate the Hinge Embedding Loss value based on the input ‘logits’ and’ labels’ (only including 1 or -1).|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.KLDivLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.KLDivLoss.html#mindspore.nn.KLDivLoss)|New|Computes the Kullback-Leibler divergence between the logits and the labels.|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.MarginRankingLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MarginRankingLoss.html#mindspore.nn.MarginRankingLoss)|New|MarginRankingLoss creates a criterion that measures the loss.|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.MultiLabelSoftMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MultiLabelSoftMarginLoss.html#mindspore.nn.MultiLabelSoftMarginLoss)|New|Calculates the MultiLabelSoftMarginLoss.|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.MultiMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MultiMarginLoss.html#mindspore.nn.MultiMarginLoss)|New|Creates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input $x$ (a 2D mini-batch Tensor) and output $y$ (which is a 1D tensor of target class indices, $0 \leq y \leq \text{x.size}(1)-1$):|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.MultilabelMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MultilabelMarginLoss.html#mindspore.nn.MultilabelMarginLoss)|New|Creates a loss criterion that minimizes the hinge loss for multi-class classification tasks.|r2.0: Ascend/GPU|Loss Function
[mindspore.nn.PoissonNLLLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.PoissonNLLLoss.html#mindspore.nn.PoissonNLLLoss)|New|Poisson negative log likelihood loss.|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.SoftMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.SoftMarginLoss.html#mindspore.nn.SoftMarginLoss)|Changed|A loss class for two-class classification problems.|r1.10: Ascend => r2.0: Ascend/GPU|Loss Function
[mindspore.nn.TripletMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TripletMarginLoss.html#mindspore.nn.TripletMarginLoss)|New|TripletMarginLoss operation.|r2.0: GPU|Loss Function
[mindspore.nn.Moments](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Moments.html#mindspore.nn.Moments)|Deleted|Calculate the mean and variance of the input x along the specified axis.|Ascend/GPU/CPU|Mathematical Operations
[mindspore.nn.MatrixDiag](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.MatrixDiag.html#mindspore.nn.MatrixDiag)|Deleted|Returns a batched diagonal tensor with a given batched diagonal values.|Ascend|Matrix Processing
[mindspore.nn.MatrixDiagPart](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.MatrixDiagPart.html#mindspore.nn.MatrixDiagPart)|Deleted|Returns the batched diagonal part of a batched tensor.|Ascend|Matrix Processing
[mindspore.nn.MatrixSetDiag](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.MatrixSetDiag.html#mindspore.nn.MatrixSetDiag)|Deleted|Modifies the batched diagonal part of a batched tensor.|Ascend|Matrix Processing
[mindspore.nn.GLU](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.GLU.html#mindspore.nn.GLU)|New|The gated linear unit function.|r2.0: Ascend/GPU/CPU|Nonlinear Activation Layer
[mindspore.nn.Softmax2d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Softmax2d.html#mindspore.nn.Softmax2d)|New|Softmax function applied to 2D features data.|r2.0: Ascend/GPU/CPU|Nonlinear Activation Layer
[mindspore.nn.ReflectionPad3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ReflectionPad3d.html#mindspore.nn.ReflectionPad3d)|New|Pad the given tensor in a reflecting way using the input boundaries as the axis of symmetry.|r2.0: Ascend/GPU/CPU|Padding Layer
[mindspore.nn.ReplicationPad1d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ReplicationPad1d.html#mindspore.nn.ReplicationPad1d)|New|Pad on W dimension of input x according to padding.|r2.0: GPU|Padding Layer
[mindspore.nn.ReplicationPad2d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ReplicationPad2d.html#mindspore.nn.ReplicationPad2d)|New|Pad on HW dimension of input x according to padding.|r2.0: GPU|Padding Layer
[mindspore.nn.ReplicationPad3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ReplicationPad3d.html#mindspore.nn.ReplicationPad3d)|New|Pad on DHW dimension of input x according to padding.|r2.0: GPU|Padding Layer
[mindspore.nn.AdaptiveAvgPool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.AdaptiveAvgPool3d.html#mindspore.nn.AdaptiveAvgPool3d)|Changed|This operator applies a 3D adaptive average pooling to an input signal composed of multiple input planes.|r1.10: GPU => r2.0: Ascend/GPU/CPU|Pooling Layer
[mindspore.nn.AdaptiveMaxPool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.AdaptiveMaxPool3d.html#mindspore.nn.AdaptiveMaxPool3d)|New|Calculates the 3D adaptive max pooling for an input Tensor.|r2.0: GPU/CPU|Pooling Layer
[mindspore.nn.AvgPool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.AvgPool3d.html#mindspore.nn.AvgPool3d)|New|Applies a 3D average pooling over an input Tensor which can be regarded as a composition of 3D input planes.|r2.0: Ascend/GPU/CPU|Pooling Layer
[mindspore.nn.FractionalMaxPool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.FractionalMaxPool3d.html#mindspore.nn.FractionalMaxPool3d)|New|Applies the 3D FractionalMaxPool operatin over input.|r2.0: GPU/CPU|Pooling Layer
[mindspore.nn.LPPool1d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.LPPool1d.html#mindspore.nn.LPPool1d)|New|Applying 1D LPPooling operation on an input Tensor can be regarded as forming a 1D input plane.|r2.0: Ascend/GPU/CPU|Pooling Layer
[mindspore.nn.LPPool2d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.LPPool2d.html#mindspore.nn.LPPool2d)|New|Applying 2D LPPooling operation on an input Tensor can be regarded as forming a 1D input plane.|r2.0: Ascend/GPU/CPU|Pooling Layer
[mindspore.nn.MaxPool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MaxPool3d.html#mindspore.nn.MaxPool3d)|New|3D max pooling operation.|r2.0: Ascend/GPU/CPU|Pooling Layer
[mindspore.nn.MaxUnpool1d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MaxUnpool1d.html#mindspore.nn.MaxUnpool1d)|New|Computes the inverse of mindspore.nn.MaxPool1d.|r2.0: GPU/CPU|Pooling Layer
[mindspore.nn.MaxUnpool2d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MaxUnpool2d.html#mindspore.nn.MaxUnpool2d)|New|Computes the inverse of mindspore.nn.MaxPool2d.|r2.0: GPU/CPU|Pooling Layer
[mindspore.nn.MaxUnpool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MaxUnpool3d.html#mindspore.nn.MaxUnpool3d)|New|Computes the inverse of mindspore.nn.MaxPool3d.|r2.0: GPU/CPU|Pooling Layer
[mindspore.nn.ChannelShuffle](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ChannelShuffle.html#mindspore.nn.ChannelShuffle)|New|Divide the channels of Tensor whose shape is $(\*, C, H, W)$ into $g$ groups to obtain a Tensor with shape $(\*, C \frac g, g, H, W)$, and transpose along the corresponding axis of $C$, $\frac{g}{}$ and $g$ to restore Tensor to the original shape.|r2.0: Ascend/GPU/CPU|Tools
[mindspore.nn.ClipByNorm](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.ClipByNorm.html#mindspore.nn.ClipByNorm)|Deleted|Clips tensor values to a maximum $L_2$-norm.|Ascend/GPU/CPU|Tools
[mindspore.nn.Identity](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Identity.html#mindspore.nn.Identity)|New|Returns a Tensor with the same shape and contents as input.|r2.0: Ascend/GPU/CPU|Tools
[mindspore.nn.L1Regularizer](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.L1Regularizer.html#mindspore.nn.L1Regularizer)|Deleted|Applies l1 regularization to weights.|Ascend/GPU/CPU|Tools
[mindspore.nn.Norm](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Norm.html#mindspore.nn.Norm)|Deleted|Computes the norm of vectors, currently including Euclidean norm, i.e., $L_2$-norm.|Ascend/GPU/CPU|Tools
[mindspore.nn.OneHot](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.OneHot.html#mindspore.nn.OneHot)|Deleted|Returns a one-hot tensor.|Ascend/GPU/CPU|Tools
[mindspore.nn.Range](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Range.html#mindspore.nn.Range)|Deleted|Creates a sequence of numbers in range [start, limit) with step size delta.|Ascend/GPU/CPU|Tools
[mindspore.nn.Roll](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Roll.html#mindspore.nn.Roll)|Deleted|Rolls the elements of a tensor along an axis.|Ascend/GPU|Tools
[mindspore.nn.Tril](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Tril.html#mindspore.nn.Tril)|Deleted|Returns a tensor, the elements above the specified main diagonal are set to zero.|Ascend/GPU/CPU|Tools
[mindspore.nn.Triu](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.Triu.html#mindspore.nn.Triu)|Deleted|Returns a tensor with elements below the kth diagonal zeroed.|Ascend/GPU/CPU|Tools
[mindspore.nn.Unflatten](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Unflatten.html#mindspore.nn.Unflatten)|New|Summary:|r2.0: Ascend/GPU/CPU|Tools
[mindspore.nn.MultiheadAttention](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MultiheadAttention.html#mindspore.nn.MultiheadAttention)|New|This is an implementation of multihead attention in the paper Attention is all you need.Given the query vector with source length, and the key and value vector with target length, the attention will be performed as the following.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.Transformer](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Transformer.html#mindspore.nn.Transformer)|New|Transformer module including encoder and decoder.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.TransformerDecoder](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TransformerDecoder.html#mindspore.nn.TransformerDecoder)|New|Transformer Decoder module with multi-layer stacked of TransformerDecoderLayer, including multihead self attention, cross attention and feedforward layer.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.TransformerDecoderLayer](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TransformerDecoderLayer.html#mindspore.nn.TransformerDecoderLayer)|New|Transformer Decoder Layer.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.TransformerEncoder](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TransformerEncoder.html#mindspore.nn.TransformerEncoder)|New|Transformer Encoder module with multi-layer stacked of TransformerEncoderLayer, including multihead self attention and feedforward layer.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.TransformerEncoderLayer](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TransformerEncoderLayer.html#mindspore.nn.TransformerEncoderLayer)|New|Transformer Encoder Layer.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.WithGradCell](https://mindspore.cn/docs/en/r1.10/api_python/nn/mindspore.nn.WithGradCell.html#mindspore.nn.WithGradCell)|Deleted|Cell that returns the gradients.|Ascend/GPU/CPU|Wrapper Layer
[mindspore.nn.PReLU](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.PReLU.html#mindspore.nn.PReLU)|Changed|PReLU activation function.|r1.10: Ascend/GPU => r2.0: Ascend/GPU/CPU|r1.10: Nonlinear Activation Function Layer => r2.0: Nonlinear Activation Layer
