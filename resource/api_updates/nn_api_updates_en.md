# mindspore.nn API Interface Change

Compared with the previous version, the added, deleted and supported platforms change information of `mindspore.nn` operators in MindSpore, is shown in the following table.

|API|Status|Description|Support Platform|Class
|:----|:----|:----|:----|:----
[mindspore.nn.ResizeBilinear](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ResizeBilinear.html#mindspore.nn.ResizeBilinear)|Changed|r2.0.0-alpha: Samples the input tensor to the given size or scale_factor by using bilinear interpolate. => r2.0: ‘nn.ResizeBilinear’ is deprecated from version 2.0 and will be removed in a future version, use mindspore.ops.ResizeBilinearV2 or mindspore.ops.interpolate() instead.|r2.0.0-alpha: Ascend/CPU/GPU => r2.0: |Image Processing Layer
[mindspore.nn.Upsample](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Upsample.html#mindspore.nn.Upsample)|New|For details, please refer to mindspore.ops.interpolate().|r2.0: Ascend/GPU/CPU|Image Processing Layer
[mindspore.nn.WarmUpLR](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.WarmUpLR.html#mindspore.nn.WarmUpLR)|Changed|Gets learning rate warming up.|r2.0.0-alpha: Ascend/GPU => r2.0: Ascend/GPU/CPU|LearningRateSchedule Class
[mindspore.nn.CTCLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.CTCLoss.html#mindspore.nn.CTCLoss)|Changed|Calculates the CTC (Connectionist Temporal Classification) loss.|r2.0.0-alpha: Ascend/CPU => r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.MultiLabelSoftMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MultiLabelSoftMarginLoss.html#mindspore.nn.MultiLabelSoftMarginLoss)|New|Calculates the MultiLabelSoftMarginLoss.|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.MultiMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MultiMarginLoss.html#mindspore.nn.MultiMarginLoss)|New|Creates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input \(x\) (a 2D mini-batch Tensor) and output \(y\) (which is a 1D tensor of target class indices, \(0 \leq y \leq \text{x.size}(1)-1\)):|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.MultilabelMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MultilabelMarginLoss.html#mindspore.nn.MultilabelMarginLoss)|New|Creates a loss criterion that minimizes the hinge loss for multi-class classification tasks.|r2.0: Ascend/GPU|Loss Function
[mindspore.nn.PoissonNLLLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.PoissonNLLLoss.html#mindspore.nn.PoissonNLLLoss)|New|Poisson negative log likelihood loss.|r2.0: Ascend/GPU/CPU|Loss Function
[mindspore.nn.TripletMarginLoss](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TripletMarginLoss.html#mindspore.nn.TripletMarginLoss)|New|TripletMarginLoss operation.|r2.0: GPU|Loss Function
[mindspore.nn.Moments](https://mindspore.cn/docs/en/r2.0.0-alpha/api_python/nn/mindspore.nn.Moments.html#mindspore.nn.Moments)|Deleted|Calculate the mean and variance of the input x along the specified axis.|Ascend/GPU/CPU|Mathematical Operations
[mindspore.nn.ProximalAdagrad](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ProximalAdagrad.html#mindspore.nn.ProximalAdagrad)|Changed|Implements the ProximalAdagrad algorithm.|r2.0.0-alpha: Ascend/GPU/CPU => r2.0: Ascend/GPU|Optimizer
[mindspore.nn.ReflectionPad3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.ReflectionPad3d.html#mindspore.nn.ReflectionPad3d)|New|Pad the given tensor in a reflecting way using the input boundaries as the axis of symmetry.|r2.0: Ascend/GPU/CPU|Padding Layer
[mindspore.nn.AdaptiveAvgPool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.AdaptiveAvgPool3d.html#mindspore.nn.AdaptiveAvgPool3d)|Changed|This operator applies a 3D adaptive average pooling to an input signal composed of multiple input planes.|r2.0.0-alpha: GPU => r2.0: Ascend/GPU/CPU|Pooling Layer
[mindspore.nn.AvgPool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.AvgPool3d.html#mindspore.nn.AvgPool3d)|Changed|Applies a 3D average pooling over an input Tensor which can be regarded as a composition of 3D input planes.|r2.0.0-alpha: Ascend/CPU => r2.0: Ascend/GPU/CPU|Pooling Layer
[mindspore.nn.FractionalMaxPool2d](https://mindspore.cn/docs/en/r2.0.0-alpha/api_python/nn/mindspore.nn.FractionalMaxPool2d.html#mindspore.nn.FractionalMaxPool2d)|Deleted|Applies a 2D fractional max pooling to an input signal composed of multiple input planes.|CPU|Pooling Layer
[mindspore.nn.MaxPool3d](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MaxPool3d.html#mindspore.nn.MaxPool3d)|Changed|3D max pooling operation.|r2.0.0-alpha: GPU => r2.0: Ascend/GPU/CPU|Pooling Layer
[mindspore.nn.Identity](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Identity.html#mindspore.nn.Identity)|New|Returns a Tensor with the same shape and contents as input.|r2.0: Ascend/GPU/CPU|Tools
[mindspore.nn.Unflatten](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Unflatten.html#mindspore.nn.Unflatten)|New|Summary:|r2.0: Ascend/GPU/CPU|Tools
[mindspore.nn.MultiheadAttention](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.MultiheadAttention.html#mindspore.nn.MultiheadAttention)|New|This is an implementation of multihead attention in the paper Attention is all you need.Given the query vector with source length, and the key and value vector with target length, the attention will be performed as the following.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.Transformer](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.Transformer.html#mindspore.nn.Transformer)|New|Transformer module including encoder and decoder.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.TransformerDecoder](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TransformerDecoder.html#mindspore.nn.TransformerDecoder)|New|Transformer Decoder module with multi-layer stacked of TransformerDecoderLayer, including multihead self attention, cross attention and feedforward layer.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.TransformerDecoderLayer](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TransformerDecoderLayer.html#mindspore.nn.TransformerDecoderLayer)|New|Transformer Decoder Layer.|r2.0.0-alpha: r2.0.0-alpha: r2.0.0-alpha: r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.TransformerEncoder](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TransformerEncoder.html#mindspore.nn.TransformerEncoder)|New|Transformer Encoder module with multi-layer stacked of TransformerEncoderLayer, including multihead self attention and feedforward layer.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.TransformerEncoderLayer](https://mindspore.cn/docs/en/r2.0/api_python/nn/mindspore.nn.TransformerEncoderLayer.html#mindspore.nn.TransformerEncoderLayer)|New|Transformer Encoder Layer.|r2.0: Ascend/GPU/CPU|Transformer Layer
[mindspore.nn.WithGradCell](https://mindspore.cn/docs/en/r2.0.0-alpha/api_python/nn/mindspore.nn.WithGradCell.html#mindspore.nn.WithGradCell)|Deleted|Cell that returns the gradients.|Ascend/GPU/CPU|Wrapper Layer
