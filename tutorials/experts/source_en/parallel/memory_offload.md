# Heterogeneous Storage

[![View Source On Gitee](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png)](https://gitee.com/mindspore/docs/blob/master/tutorials/experts/source_en/parallel/memory_offload.md)

## Overview

In recent years Transformer-based large models have made rapid progress in various downstream tasks in nlp and vision, and often the larger the model, the higher the accuracy achieved in downstream tasks. The model size develops from hundreds of millions to hundreds of billions, however, large model training consumes a large amount of computational storage resources and the training overhead is huge.

Large model training is limited by the size of the video memory, and the number of model parameters that can be stored on a single card is limited. With model parallel, we can split large models into different machines, and after introducing the necessary inter-process communication, we can conduct collaborative training in clusters, where the model size is proportional to the machine size. At the same time, when the model size exceeds the memory capacity of a single machine, the overhead of inter-machine communication in model parallel will become larger, and the resource utilization will decrease significantly. How to train larger models on a single machine and avoid inter-machine communication in model parallel has become the key to improve the performance of large model training.

Heterogeneous storage management enables 10x to 100x storage expansion of model parameters, thus breaking the memory limitation of large model training and realizing low-cost large model training. This tutorial will explain the basic principles of heterogeneous storage management and introduce the related configuration parameters and their use. With this feature, developers can use the same hardware to train larger models.

## Basic Principles of Heterogeneous Storage Management

During training, the main stored data consists of parameters and intermediate results:

* Parameters: data such as the weights of the model and the state of the optimizer, which need to be stored all the time during the training process.
* Intermediate results: data generated by the computation in the forward, backward and optimization processes, which can be released and deleted after the corresponding computation is completed.

Through heterogeneous storage management, parameters or intermediate results that do not need to participate in computation temporarily can be copied to the memory of Host side or even hard disk storage during the training process, and then copied and restored to the device side when the data is needed to participate in computation. By the above means, the model size that can be trained by the same hardware device can be increased.

![image.png](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/experts/source_zh_cn/parallel/images/memory_offload.png)

## Code Example

Taking the ResNet-50 network as an example, for the code implementation, refers to [example](https://gitee.com/mindspore/docs/tree/master/docs/sample_code/memory_offload). The directory structure is shown below, where resnet.py is the ResNet-50 network implementation, cifa_resnet50.py is the training script, and run.sh is the execution script.

```text
└─ sample_code
    ├─ memory_offload
       ├── resnet.py
       ├── cifa_resnet50.py
       ├── run.sh
    ...
```

```shell
bash run.sh Ascend 512 OFF
```

When training with batch_size=512 without turning on heterogeneous storage, an 'Out of Memory' error occurs due to insufficient memory space:

```bash
----------------------------------------------------
- Framework Error Message:
----------------------------------------------------
Out of Memory!!! Request memory size: 33100113920B, Memory Statistic:
Device HBM memory size: 32768M
MindSpore Used memory size: 30684M
MindSpore memory base address: 0x124140000000
Total Static Memory size: 496M
Total Dynamic memory size: 0M
Dynamic memory size of this graph: 0M

Please try to reduce 'batch_size' or check whether exists extra large shape. For more details, please refer to 'Out of Memory' at https://www.mindspore.cn .

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_kernel_executor.cc:252 PreprocessBeforeRunGraph
mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:169 MallocDynamicDevMem
```

After turning on heterogeneous storage, batch_size=512 is used normally during training:

```bash
bash run.sh Ascend 512 ON
```

```bash
epoch: 1 step: 111, loss is 2.1563000679016113
epoch: 1 step: 112, loss is 2.1421408653259277
epoch: 1 step: 113, loss is 2.129314422607422
epoch: 1 step: 114, loss is 2.127141237258911
epoch: 1 step: 115, loss is 2.1191487312316895
epoch: 1 step: 116, loss is 2.1299633979797363
epoch: 1 step: 117, loss is 2.138218402862549
```

Heterogeneous storage configuration and switch code:

```python
import mindspore

offload_config = {"offload_param": "cpu",
                  "auto_offload": False,
                  "offload_cpu_size": "512GB",
                  "offload_disk_size": "1024GB",
                  "offload_path": "./offload/",
                  "host_mem_block_size":"1GB",
                  "enable_aio": True,
                  "enable_pinned_mem": True}
mindspore.set_context(mode=mindspore.GRAPH_MODE, memory_offload='ON', max_device_memory='30GB')
mindspore.set_offload_context(offload_config=offload_config)
```

``offload_config`` is the configuration option for heterogeneous storage, where

* ``"offload_param": "cpu"`` sets the model parameters to be stored on the cpu memory, loaded to the device side only when the data is needed to be used during training, and then unloaded to the cpu memory as soon as use is complete.
* ``"auto_offload": False`` sets the auto-offload policy to be turned off and the parameter data will be installed with the previous configuration option.
* ``"offload_cpu_size": "512GB", "offload_disk_size": "1024GB"`` sets the amount of cpu memory and disk size that can be used for offload, respectively.
* ``"offload_path": ". /offload/"`` sets the path to the disk file to be used for the offload.
* ``"enable_pinned_mem": True`` sets page locking to be turned on, which when turned on speeds up copying between HBM-CPU memory.
* ``"host_mem_block_size": "1GB"`` sets the block size of cpu page locking memory pool.
* ``"enable_aio": True`` sets to enable asynchronous IO for files, when enabled it speeds up DDR-disk-to-disk copying. (Requires compilation with -o option, and only supports Linux environments with aio installed)

In this example, the offload_param parameter is configured as "cpu" and auto_offload is not enabled. The parameters will be stored in the cpu memory during the whole training process. When some parameters are needed to participate in the computation, the data will be copied to the device side, and after the computation is completed, it will be copied back to the cpu memory again.

### Automatic Generation of offload Strategy

In addition to strictly installing user ``"offload_param"`` configurations for data copying, MindSpore also supports automatic generation of heterogeneous storage strategy. MindSpore can analyze the network video memory usage information and combine it with ``"max_device_memory"``, ``"offload_ cpu_size"``, ``"offload_disk_size"``, ``"hbm_ratio"``, ``"cpu_ratio"`` configured by the user to generate a heterogeneous storage strategy, and then move the data across multiple storage media according to the established strategy.

```python
import mindspore

offload_config = {"offload_path": "./offload/",
                  "auto_offload": True,
                  "offload_param": "cpu",
                  "offload_cpu_size": "512GB",
                  "offload_disk_size": "1024GB",
                  "host_mem_block_size":"1GB",
                  "enable_aio": True,
                  "enable_pinned_mem": True}
mindspore.set_context(mode=mindspore.GRAPH_MODE, memory_offload='ON', max_device_memory='30GB')
mindspore.set_offload_context(offload_config=offload_config)
```

In this example, ``"auto_offload": True`` is set, and ``"offload_param"`` only affects the initial storage location of the parameter, and the framework adjusts the weights and intermediate results storage location during the computation process according to the generated strategy.