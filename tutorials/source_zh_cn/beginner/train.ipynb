{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练\n",
    "\n",
    "[![下载Notebook](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/tutorials/zh_cn/beginner/mindspore_train.ipynb)&emsp;[![下载样例代码](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/tutorials/zh_cn/beginner/mindspore_train.py)&emsp;[![查看源文件](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/master/tutorials/source_zh_cn/beginner/train.ipynb)\n",
    "\n",
    "模型训练一般分为四个步骤：\n",
    "\n",
    "1. 构建数据集。\n",
    "2. 定义神经网络。\n",
    "3. 定义超参、损失函数及优化器。\n",
    "4. 输入数据集进行训练与评估。\n",
    "\n",
    "通过上面章节的学习，我们已经学会如何构建数据集和创建模型，本章将主要介绍如何设置超参和训练模型。本章以MNIST数据集和LeNet网络为例，介绍使用MNIST数据集训练LeNet网络。\n",
    "\n",
    "从数据处理和创建网络章节中加载先前代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.vision as vision\n",
    "import mindspore.nn as nn\n",
    "from mindspore.common.initializer import Normal\n",
    "\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "\n",
    "def download_dataset(dataset_url, path):\n",
    "    filename = dataset_url.split(\"/\")[-1]\n",
    "    save_path = os.path.join(path, filename)\n",
    "    if os.path.exists(save_path):\n",
    "        return\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    res = requests.get(dataset_url, stream=True, verify=False)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        for chunk in res.iter_content(chunk_size=512):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(\"The {} file is downloaded and saved in the path {} after processing\".format(os.path.basename(dataset_url),\n",
    "                                                                                       path))\n",
    "\n",
    "\n",
    "train_path = \"datasets/MNIST_Data/train\"\n",
    "test_path = \"datasets/MNIST_Data/test\"\n",
    "\n",
    "# 下载数据集\n",
    "download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-labels-idx1-ubyte\",\n",
    "                 train_path)\n",
    "download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-images-idx3-ubyte\",\n",
    "                 train_path)\n",
    "download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-labels-idx1-ubyte\",\n",
    "                 test_path)\n",
    "download_dataset(\"https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-images-idx3-ubyte\",\n",
    "                 test_path)\n",
    "\n",
    "\n",
    "def create_dataset(data_path, batch_size=16, image_size=32):\n",
    "    # 加载MINIST数据集\n",
    "    dataset = ds.MnistDataset(data_path)\n",
    "\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "\n",
    "    # 图像增强操作\n",
    "    trans = [\n",
    "        vision.Resize(size=image_size),\n",
    "        vision.Rescale(rescale, shift),\n",
    "        vision.HWC2CHW(),\n",
    "    ]\n",
    "    dataset = dataset.map(operations=trans, input_columns=[\"image\"])\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 自定义网络\n",
    "class LeNet(nn.Cell):\n",
    "    def __init__(self, num_classes=10, num_channel=1):\n",
    "        super(LeNet, self).__init__()\n",
    "        layers = [nn.Conv2d(num_channel, 6, 5, pad_mode='valid'),\n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                  nn.Conv2d(6, 16, 5, pad_mode='valid'),\n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                  nn.Flatten(),\n",
    "                  nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02)),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Dense(120, 84, weight_init=Normal(0.02)),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Dense(84, num_classes, weight_init=Normal(0.02))]\n",
    "        # 使用CellList对网络进行管理\n",
    "        self.build_block = nn.CellList(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        # for循环执行网络\n",
    "        for layer in self.build_block:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 定义神经网络\n",
    "network = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参（Hyper-parametric）\n",
    "\n",
    "超参是可以调整的参数，可以控制模型训练优化的过程，不同的超参数值可能会影响模型训练和收敛速度。目前深度学习模型多采用批量随机梯度下降算法进行优化，随机梯度下降算法的原理如下：\n",
    "\n",
    "$$w_{t+1}=w_{t}-\\eta \\frac{1}{n} \\sum_{x \\in \\mathcal{B}} \\nabla l\\left(x, w_{t}\\right)$$\n",
    "\n",
    "式中，$n$是批量大小(batch size)，$η$是学习率(learning rate)；另外，$w_{t}$为训练轮次t中权重参数，$\\nabla l$为损失函数的导数。可知道除了梯度本身，这两个因子直接决定了模型的权重更新，从优化本身来看它们是影响模型性能收敛最重要的参数。一般会定义以下超参用于训练：\n",
    "\n",
    "训练轮次（epoch）：训练时遍历数据集的次数。\n",
    "\n",
    "批次大小（batch size）：数据集进行分批读取训练，设定每个批次数据的大小。batch size过小，花费时间多，同时梯度震荡严重，不利于收敛；batch size过大，不同batch的梯度方向没有任何变化，容易陷入局部极小值，因此需要选择合适的batch size，可以有效提高模型精度、全局收敛。\n",
    "\n",
    "学习率（learning rate）：如果学习率偏小，会导致收敛的速度变慢，如果学习率偏大则可能会导致训练不收敛等不可预测的结果。梯度下降法是一个广泛被用来最小化模型误差的参数优化算法。梯度下降法通过多次迭代，并在每一步中最小化损失函数来估计模型的参数。学习率就是在迭代过程中，会控制模型的学习进度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数\n",
    "\n",
    "**损失函数**用来评价模型的**预测值**和**目标值**之间的误差，在这里，使用`SoftmaxCrossEntropyWithLogits`计算预测值与真实值之间的交叉熵。代码用例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义优化器\n",
    "\n",
    "**优化器函数**用于计算和更新梯度，模型优化算法的选择直接关系到最终模型的性能。有时候最终模型效果不好，未必是特征或者模型设计的问题，很有可能是优化算法的问题。在这里，我们使用`Momentum`优化器。`mindspore.nn`也提供了许多其他常用的优化器函数，如`Adam`、`SGD`、`RMSProp`等。\n",
    "\n",
    "我们需要构建一个Optimizer对象，这个对象能够基于计算得到的梯度对参数进行更新。为了构建一个Optimizer，需要给它一个包含可优化的参数，如网络中所有可以训练的parameter，即设置优化器的入参为`network.trainable_params()`。\n",
    "\n",
    "然后，设置Optimizer的参数选项，比如学习率、权重衰减等。代码样例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_opt = nn.Momentum(network.trainable_params(), learning_rate=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练流程\n",
    "\n",
    "首先定义前向网络`forward`，输出正向传播网络的损失值；然后定义单个step训练流程`train_step`，通过反向传播实现网络权重的更新。最后定义训练流程`train_epoch`，传入训练数据集和模型，实现单个epoch的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.ops as ops\n",
    "\n",
    "\n",
    "# 前向网络\n",
    "def forward(inputs, targets):\n",
    "    outputs = network(inputs)\n",
    "    loss = net_loss(outputs, targets)\n",
    "    return loss\n",
    "\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward, None, net_opt.parameters)\n",
    "\n",
    "\n",
    "# 定义单个step训练流程，实现网络权重的更新\n",
    "def train_step(inputs, targets):\n",
    "    loss, grads = grad_fn(inputs, targets)\n",
    "    net_opt(grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 定义单个epoch训练流程\n",
    "def train_epoch(dataset, network):\n",
    "    # 设置网络为训练模式\n",
    "    network.set_train()\n",
    "    # 使用数据集对网络进行训练\n",
    "    for data in dataset.create_dict_iterator():\n",
    "        loss = train_step(ms.Tensor(data['image'], ms.float32), ms.Tensor(data[\"label\"], ms.int32))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义验证流程\n",
    "\n",
    "定义验证流程`evaluate_epoch`，传入待验证的数据集和训练好的网络，计算网络分类的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def evaluate_epoch(dataset, network):\n",
    "    size = dataset.get_dataset_size()\n",
    "    accuracy = 0\n",
    "\n",
    "    for data in dataset.create_dict_iterator():\n",
    "        output = network(ms.Tensor(data['image'], ms.float32))\n",
    "        acc = np.equal(output.argmax(1).asnumpy(), data[\"label\"].asnumpy())\n",
    "        accuracy += np.mean(acc)\n",
    "    accuracy /= size\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练与评估\n",
    "\n",
    "定义好训练流程和验证流程后，加载训练数据集和验证数据集后，即可进行模型的训练与评估，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVENT] (PID29692) 2022-09-08-10:55:46.568.557 Start compiling 'after_grad' and it will take a while. Please wait...\n",
      "[EVENT] (PID29692) 2022-09-08-10:55:46.695.443 End compiling 'after_grad'.\n",
      "[EVENT] (PID29692) 2022-09-08-10:55:46.723.607 Start compiling 'Momentum.construct' and it will take a while. Please wait...\n",
      "[EVENT] (PID29692) 2022-09-08-10:55:46.764.006 End compiling 'Momentum.construct'.\n",
      "[EVENT] (PID29692) 2022-09-08-10:55:51.390.778 Start compiling 'LeNet.construct' and it will take a while. Please wait...\n",
      "[EVENT] (PID29692) 2022-09-08-10:55:51.428.831 End compiling 'LeNet.construct'.\n",
      "--------------------\n",
      "Epoch:[0/10], Train loss:2.3203, Accuracy:0.113, Time:5.26s, \n",
      "--------------------\n",
      "Epoch:[1/10], Train loss:0.0699, Accuracy:0.956, Time:4.84s, \n",
      "--------------------\n",
      "Epoch:[2/10], Train loss:0.0157, Accuracy:0.976, Time:4.63s, \n",
      "--------------------\n",
      "Epoch:[3/10], Train loss:0.0570, Accuracy:0.974, Time:4.54s, \n",
      "--------------------\n",
      "Epoch:[4/10], Train loss:0.0255, Accuracy:0.986, Time:4.64s, \n",
      "--------------------\n",
      "Epoch:[5/10], Train loss:0.2859, Accuracy:0.986, Time:4.74s, \n",
      "--------------------\n",
      "Epoch:[6/10], Train loss:0.0005, Accuracy:0.985, Time:4.67s, \n",
      "--------------------\n",
      "Epoch:[7/10], Train loss:0.0166, Accuracy:0.989, Time:4.73s, \n",
      "--------------------\n",
      "Epoch:[8/10], Train loss:0.0046, Accuracy:0.988, Time:4.61s, \n",
      "--------------------\n",
      "Epoch:[9/10], Train loss:0.0003, Accuracy:0.987, Time:4.67s, \n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.ops as ops\n",
    "import time\n",
    "\n",
    "# 加载训练数据集\n",
    "dataset_train = create_dataset(train_path, batch_size)\n",
    "# 加载测试数据集\n",
    "dataset_test = create_dataset(test_path, batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    result = train_epoch(dataset_train, network)\n",
    "    acc = evaluate_epoch(dataset_test, network)\n",
    "    end = time.time()\n",
    "    time_ = round(end - start, 2)\n",
    "\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Epoch:[{epoch}/{epochs}], \"\n",
    "          f\"Train loss:{result.asnumpy():5.4f}, \"\n",
    "          f\"Accuracy:{acc:5.3f}, \"\n",
    "          f\"Time:{time_}s, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程中会打印loss值，loss值会波动，但总体来说loss值会逐步减小，精度逐步提高。每个人运行的loss值有一定随机性，不一定完全相同。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
