{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对抗示例生成\n",
    "\n",
    "[![](https://gitee.com/mindspore/docs/raw/r1.3/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/r1.3/tutorials/source_zh_cn/intermediate/image_and_video/adversarial_example_generation.ipynb)\n",
    "\n",
    "近年来随着数据、计算能力、理论的不断发展演进，深度学习在图像、文本、语音、自动驾驶等众多领域都得到了广泛应用。与此同时，人们也越来越关注各类模型在使用过程中的安全问题，因为AI模型很容易受到外界有意无意的攻击而产生错误的结果。在本案例中，我们将以梯度符号攻击FGSM（Fast Gradient Sign Method）为例，演示此类攻击是如何误导模型的。\n",
    "\n",
    "## 对抗样本定义\n",
    "\n",
    "Szegedy在2013年最早提出对抗样本的概念：在原始样本处加入人类无法察觉的微小扰动，使得深度模型性能下降，这种样本即对抗样本。如下图所示，本来预测为“panda”的图像在添加噪声之后，模型就将其预测为“gibbon”，右边的样本就是一个对抗样本：\n",
    "\n",
    "![fgsm-panda-image](images/panda.png)\n",
    "\n",
    "> 图片来自[Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)。\n",
    "\n",
    "\n",
    "## 攻击方法\n",
    "\n",
    "对模型的攻击方法可以按照以下方法分类：\n",
    "\n",
    "1. 攻击者掌握的信息多少：\n",
    "\n",
    "    1.1 白盒攻击：攻击者具有对模型的全部知识和访问权限，包括模型结构、权重、输入、输出。攻击者在产生对抗性攻击数据的过程中能够与模型系统有所交互。攻击者可以针对被攻击模型的特性设计特定的攻击算法。\n",
    "\n",
    "    1.2 黑盒攻击：与白盒攻击相反，攻击者仅具有关于模型的有限知识。攻击者对模型的结构权重一无所知，仅了解部分输入输出。\n",
    "\n",
    "2. 攻击者的目的：\n",
    "\n",
    "    2.1 有目标的攻击：攻击者将模型结果误导为特定分类。\n",
    "\n",
    "    2.2 无目标的攻击：攻击者只想产生错误结果，而不在乎新结果是什么。\n",
    "\n",
    "本案例中用到的FGSM是一种白盒攻击方法，既可以是有目标也可以是无目标攻击。\n",
    "\n",
    "更多的模型安全功能可参考[MindArmour](https://www.mindspore.cn/mindarmour)，现支持FGSM、LLC、Substitute Attack等多种对抗样本生成方法，并提供对抗样本鲁棒性模块、Fuzz Testing模块、隐私保护与评估模块，帮助用户增强模型安全性。\n",
    "\n",
    "### 梯度符号攻击（FGSM）\n",
    "\n",
    "正常分类网络的训练会定义一个损失函数，用于衡量模型输出值与样本真实标签的距离，通过反向传播计算模型梯度，梯度下降更新网络参数，减小损失值，提升模型精度。\n",
    "\n",
    "FGSM（Fast Gradient Sign Method）是一种简单高效的对抗样本生成方法。不同于正常分类网络的训练过程，FGSM计算loss对于输入的梯度$\\nabla_x J(\\theta ,x ,y)$，这个梯度表征了loss对于输入变化的敏感性。然后在原始输入加上上述梯度，使得loss值增大，模型对于改造后的输入样本分类效果变差，达到攻击效果。对抗样本的另一要求是生成样本与原始样本的差异要尽可能的小，使用sign函数可以使得修改图片时尽可能的均匀。\n",
    "\n",
    "产生的对抗扰动用公式可以表示为：\n",
    "\n",
    "$$ \\eta  = \\varepsilon  sign(\\nabla_x  J(\\theta))$$\n",
    "\n",
    "对抗样本的产生可公式化为：\n",
    "\n",
    "$$ perturbed\\_image = image + epsilon \\times sign(data\\_grad) = x + \\epsilon \\times sign(\\nabla_x J(\\theta ,x ,y)) $$\n",
    "\n",
    "其中，\n",
    "\n",
    "- $x$：正确分类为“Pandas”的原始输入图像。\n",
    "- $y$：是$x$的输出。\n",
    "- $\\theta$：模型参数。\n",
    "- $\\varepsilon$：攻击系数。\n",
    "- $J(\\theta, x, y)$：训练网络的损失。\n",
    "- $\\nabla_x  J(\\theta)$：反向传播梯度。\n",
    "\n",
    "## 实现攻击\n",
    "\n",
    "本案例将使用MNIST训练一个精度达标的LeNet网络，然后运行上文中所提到的FGSM攻击方法，实现错误分类的效果。\n",
    "\n",
    "首先导入模型训练需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型训练需要的库\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import Tensor, context, Model, load_checkpoint, load_param_into_net\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.train.callback import LossMonitor\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore.dataset.vision import Inter\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用`GRAPH_MODE`在CPU/GPU/Ascend中运行本案例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.set_context(mode=context.GRAPH_MODE, device_target='Ascend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练LeNet网络\n",
    "\n",
    "实验中使用LeNet作为演示模型完成图像分类，这里先定义网络并使用MNIST数据集进行训练。\n",
    "\n",
    "定义LeNet网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Cell):\n",
    "\n",
    "    def __init__(self, num_class=10, num_channel=1):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\n",
    "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = LeNet5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载MINIST数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./datasets/MNIST_Data/train ./datasets/MNIST_Data/test\n",
    "!wget -NP ./datasets/MNIST_Data/train https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-labels-idx1-ubyte\n",
    "!wget -NP ./datasets/MNIST_Data/train https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/train-images-idx3-ubyte\n",
    "!wget -NP ./datasets/MNIST_Data/test https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-labels-idx1-ubyte\n",
    "!wget -NP ./datasets/MNIST_Data/test https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/mnist/t10k-images-idx3-ubyte\n",
    "!tree ./datasets/MNIST_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行数据处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_path, batch_size=1, repeat_size=1,\n",
    "                   num_parallel_workers=1):\n",
    "\n",
    "    # 定义数据集\n",
    "    mnist_ds = ds.MnistDataset(data_path)\n",
    "    resize_height, resize_width = 32, 32\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "    rescale_nml = 1 / 0.3081\n",
    "    shift_nml = -1 * 0.1307 / 0.3081\n",
    "\n",
    "    # 定义所需要操作的map映射\n",
    "    resize_op = CV.Resize((resize_height, resize_width), interpolation=Inter.LINEAR)\n",
    "    rescale_nml_op = CV.Rescale(rescale_nml, shift_nml)\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    type_cast_op = C.TypeCast(mstype.int32)\n",
    "\n",
    "    # 使用map映射函数，将数据操作应用到数据集\n",
    "    mnist_ds = mnist_ds.map(operations=type_cast_op, input_columns=\"label\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=resize_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=rescale_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=rescale_nml_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=hwc2chw_op, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "\n",
    "    # 进行shuffle、batch操作\n",
    "    buffer_size = 10000\n",
    "    mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)\n",
    "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return mnist_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义优化器与损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "net_opt = nn.Momentum(net.trainable_params(), learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ck = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
    "ckpoint = ModelCheckpoint(prefix=\"checkpoint_lenet\", config=config_ck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义LeNet网络的训练函数和测试函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(model, data_path):\n",
    "    ds_eval = create_dataset(os.path.join(data_path, \"test\"))\n",
    "    acc = model.eval(ds_eval, dataset_sink_mode=False)\n",
    "    print(\"{}\".format(acc))\n",
    "    \n",
    "def train_net(model, epoch_size, data_path, repeat_size, ckpoint_cb, sink_mode):\n",
    "    ds_train = create_dataset(os.path.join(data_path, \"train\"), 32, repeat_size)\n",
    "    model.train(epoch_size, ds_train, callbacks=[ckpoint_cb, LossMonitor(125)], dataset_sink_mode=sink_mode)\n",
    "\n",
    "train_epoch = 1\n",
    "mnist_path = \"./datasets/MNIST_Data/\"\n",
    "dataset_size = 1\n",
    "model = Model(net, net_loss, net_opt, metrics={\"Accuracy\": nn.Accuracy()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练LeNet网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 125, loss is 2.2939456\n",
      "epoch: 1 step: 250, loss is 2.3160274\n",
      "epoch: 1 step: 375, loss is 2.2910666\n",
      "epoch: 1 step: 500, loss is 2.3069649\n",
      "epoch: 1 step: 625, loss is 2.3095846\n",
      "epoch: 1 step: 750, loss is 2.294733\n",
      "epoch: 1 step: 875, loss is 1.8178409\n",
      "epoch: 1 step: 1000, loss is 0.70218444\n",
      "epoch: 1 step: 1125, loss is 0.10911212\n",
      "epoch: 1 step: 1250, loss is 0.31053308\n",
      "epoch: 1 step: 1375, loss is 0.03824125\n",
      "epoch: 1 step: 1500, loss is 0.20801516\n",
      "epoch: 1 step: 1625, loss is 0.08320282\n",
      "epoch: 1 step: 1750, loss is 0.33072343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1875, loss is 0.15156953\n"
     ]
    }
   ],
   "source": [
    "train_net(model, train_epoch, mnist_path, dataset_size, ckpoint, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "测试此时的网络，可以观察到LeNet已经达到比较高的精度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.9602}\n"
     ]
    }
   ],
   "source": [
    "test_net(model, mnist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "加载此时的网络参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_dict = load_checkpoint(\"checkpoint_lenet-1_1875.ckpt\")\n",
    "load_param_into_net(net, param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 实现FGSM\n",
    "\n",
    "在得到精准的LeNet网络之后，下面将会采用FSGM攻击方法，在图像中加载噪声后重新进行测试。首先根据上文中提到的公式定义FGSM攻击函数`attack`。\n",
    "\n",
    "$$ \\eta  = \\varepsilon  sign(\\nabla_x  J(\\theta))$$\n",
    "\n",
    "$$ perturbed\\_image = image + epsilon \\times sign(data\\_grad) = x + \\epsilon \\times sign(\\nabla_x J(\\theta ,x ,y)) $$\n",
    "\n",
    "`attcak`中图像`image`、攻击系数`epsilon`和反向梯度`data_grad`都来自外部输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def attack(image, epsilon, data_grad):\n",
    "    sign = ops.Sign()\n",
    "    sign_data_grad = sign(data_grad)\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 测试攻击效果\n",
    "\n",
    "现在使用定义好的`attack`函数重新对网络进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSMTest(net, ds_test, epsilon):\n",
    "    # 使用Model接口包装模型\n",
    "    pre_model = Model(net, net_loss, net_opt, metrics={\"Accuracy\": nn.Accuracy()})\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    # 重新对ds_test测试集中的图片进行测试\n",
    "    for data in ds_test:\n",
    "        label = data[\"label\"].asnumpy()\n",
    "        image_tensor = Tensor(data['image'])\n",
    "        pre_output = pre_model.predict(image_tensor)\n",
    "        predicted = np.argmax(pre_output.asnumpy(), axis=1)\n",
    "        if predicted[0] != label[0]:\n",
    "            continue\n",
    "        # 获得反向梯度\n",
    "        grad = ops.composite.GradOperation()\n",
    "        net_with_criterion = nn.WithLossCell(net, net_loss)\n",
    "        image_grad = grad(net_with_criterion)(image_tensor, Tensor(data['label']))\n",
    "        # 调用攻击函数实现攻击\n",
    "        perturbed_data = attack(Tensor(data['image']), epsilon, image_grad)\n",
    "        # 统计攻击后的精确度\n",
    "        perturbed_predict = pre_model.predict(perturbed_data)\n",
    "        perturbed_result = np.argmax(perturbed_predict.asnumpy(), axis=1)\n",
    "        if perturbed_result[0] == label[0]:\n",
    "            correct += 1\n",
    "        if perturbed_result[0] != label[0]:\n",
    "            incorrect += 1\n",
    "    perturbed_accuracy = correct / (correct + incorrect)\n",
    "    print (\"Accuracy = \", perturbed_accuracy)\n",
    "    return perturbed_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行攻击\n",
    "\n",
    "由FGSM攻击公式中可以看出，攻击系数$\\varepsilon$越大，对梯度的改变就越大。当$\\varepsilon$ 为零时则攻击效果不体现。\n",
    "\n",
    "$$ \\eta  = \\varepsilon  sign(\\nabla_x  J(\\theta)) $$\n",
    "\n",
    "现在，先观察当$\\varepsilon$ = 0 时的测试结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "# 定义测试数据集，batch_size=1表示每次取出一张图片\n",
    "ds_test = create_dataset(os.path.join(mnist_path, \"test\"), batch_size=1).create_dict_iterator()\n",
    "# 运行攻击\n",
    "epsilon = 0\n",
    "final_acc = FGSMTest(net, ds_test, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "设定$\\varepsilon$ = 0.8，再次观察攻击效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.10975993290701332\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.8\n",
    "final_acc = FGSMTest(net, ds_test, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "可以看到，此时LeNet模型的精度大幅降低。以直观的图片为例，右侧图片与左侧图片几乎没有明显变化，但是FGSM方法成功误导了模型，使模型将其错误地归属到其他类别中。\n",
    "\n",
    "![attack-result](images/attack_result.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore1.2_gpu",
   "language": "python",
   "name": "liuxiao_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
