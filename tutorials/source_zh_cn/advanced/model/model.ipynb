{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![在线运行](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_modelarts.png)](https://authoring-modelarts-cnnorth4.huaweicloud.com/console/lab?share-url-b64=aHR0cHM6Ly9vYnMuZHVhbHN0YWNrLmNuLW5vcnRoLTQubXlodWF3ZWljbG91ZC5jb20vbWluZHNwb3JlLXdlYnNpdGUvbm90ZWJvb2svcjIuMC90dXRvcmlhbHMvemhfY24vYWR2YW5jZWQvbW9kZWwvbWluZHNwb3JlX21vZGVsLmlweW5i=&imageid=b8671c1e-c439-4ae2-b9c6-69b46db134ae)&emsp;[![下载Notebook](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_notebook.png)](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/r2.0/tutorials/zh_cn/advanced/model/mindspore_model.ipynb)&emsp;[![下载样例代码](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_download_code.png)](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/r2.0/tutorials/zh_cn/advanced/model/mindspore_model.py)&emsp;[![查看源文件](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/r2.0/tutorials/source_zh_cn/advanced/model/model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高阶封装：Model\n",
    "\n",
    "通常情况下，定义训练和评估网络并直接运行，已经可以满足基本需求。\n",
    "\n",
    "一方面，`Model`可以在一定程度上简化代码。例如：无需手动遍历数据集；在不需要自定义`nn.TrainOneStepCell`的场景下，可以借助`Model`自动构建训练网络；可以使用`Model`的`eval`接口进行模型评估，直接输出评估结果，无需手动调用评价指标的`clear`、`update`、`eval`函数等。\n",
    "\n",
    "另一方面，`Model`提供了很多高阶功能，如数据下沉、混合精度等，在不借助`Model`的情况下，使用这些功能需要花费较多的时间仿照`Model`进行自定义。\n",
    "\n",
    "本文档首先对MindSpore的Model进行基本介绍，然后重点讲解如何使用`Model`进行模型训练、评估和推理。\n",
    "\n",
    "![model](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.0/tutorials/source_zh_cn/advanced/model/images/model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from mindspore import nn\n",
    "from mindspore.dataset import vision, transforms\n",
    "from mindspore.dataset import MnistDataset\n",
    "from mindspore.train import Model, CheckpointConfig, ModelCheckpoint, LossMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model基本介绍\n",
    "\n",
    "[Model](https://www.mindspore.cn/docs/zh-CN/r2.0/api_python/train/mindspore.train.Model.html#mindspore.train.Model)是MindSpore提供的高阶API，可以进行模型训练、评估和推理。其接口的常用参数如下：\n",
    "\n",
    "- `network`：用于训练或推理的神经网络。\n",
    "- `loss_fn`：所使用的损失函数。\n",
    "- `optimizer`：所使用的优化器。\n",
    "- `metrics`：用于模型评估的评价函数。\n",
    "- `eval_network`：模型评估所使用的网络，未定义情况下，`Model`会使用`network`和`loss_fn`进行封装。\n",
    "\n",
    "`Model`提供了以下接口用于模型训练、评估和推理：\n",
    "\n",
    "- `fit`：边训练边评估模型。\n",
    "- `train`：用于在训练集上进行模型训练。\n",
    "- `eval`：用于在验证集上进行模型评估。\n",
    "- `predict`：用于对输入的一组数据进行推理，输出预测结果。\n",
    "\n",
    "### 使用Model接口\n",
    "\n",
    "对于简单场景的神经网络，可以在定义`Model`时指定前向网络`network`、损失函数`loss_fn`、优化器`optimizer`和评价函数`metrics`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载并处理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from open datasets\n",
    "from download import download\n",
    "\n",
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\" \\\n",
    "      \"notebook/datasets/MNIST_Data.zip\"\n",
    "path = download(url, \"./\", kind=\"zip\", replace=True)\n",
    "\n",
    "\n",
    "def datapipe(path, batch_size):\n",
    "    image_transforms = [\n",
    "        vision.Rescale(1.0 / 255.0, 0),\n",
    "        vision.Normalize(mean=(0.1307,), std=(0.3081,)),\n",
    "        vision.HWC2CHW()\n",
    "    ]\n",
    "    label_transform = transforms.TypeCast(mindspore.int32)\n",
    "\n",
    "    dataset = MnistDataset(path)\n",
    "    dataset = dataset.map(image_transforms, 'image')\n",
    "    dataset = dataset.map(label_transform, 'label')\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = datapipe('MNIST_Data/train', 64)\n",
    "test_dataset = datapipe('MNIST_Data/test', 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class Network(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_relu_sequential = nn.SequentialCell(\n",
    "            nn.Dense(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(512, 10)\n",
    "        )\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.dense_relu_sequential(x)\n",
    "        return logits\n",
    "\n",
    "model = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数和优化器\n",
    "\n",
    "要训练神经网络模型，需要定义损失函数和优化器函数。\n",
    "\n",
    "- 损失函数这里使用交叉熵损失函数`CrossEntropyLoss`。\n",
    "- 优化器这里使用`SGD`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = nn.SGD(model.trainable_params(), 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练及保存模型\n",
    "\n",
    "在开始训练之前，MindSpore需要提前声明网络模型在训练过程中是否需要保存中间过程和结果，因此使用`ModelCheckpoint`接口用于保存网络模型和参数，以便进行后续的Fine-tuning（微调）操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_dataset.get_dataset_size()\n",
    "config = CheckpointConfig(save_checkpoint_steps=steps_per_epoch)\n",
    "\n",
    "ckpt_callback = ModelCheckpoint(prefix=\"mnist\", directory=\"./checkpoint\", config=config)\n",
    "loss_callback = LossMonitor(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过MindSpore提供的`model.fit`接口可以方便地进行网络的训练，`LossMonitor`可以监控训练过程中`loss`值的变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 938, loss is 0.602992594242096\n",
      "Eval result: epoch 1, metrics: {'accuracy': 0.8435}\n",
      "epoch: 2 step: 938, loss is 0.2797124981880188\n",
      "Eval result: epoch 2, metrics: {'accuracy': 0.9003}\n",
      "epoch: 3 step: 938, loss is 0.32015785574913025\n",
      "Eval result: epoch 3, metrics: {'accuracy': 0.9179}\n",
      "epoch: 4 step: 938, loss is 0.17153620719909668\n",
      "Eval result: epoch 4, metrics: {'accuracy': 0.9308}\n",
      "epoch: 5 step: 938, loss is 0.18772485852241516\n",
      "Eval result: epoch 5, metrics: {'accuracy': 0.9382}\n",
      "epoch: 6 step: 938, loss is 0.45641791820526123\n",
      "Eval result: epoch 6, metrics: {'accuracy': 0.946}\n",
      "epoch: 7 step: 938, loss is 0.11519066989421844\n",
      "Eval result: epoch 7, metrics: {'accuracy': 0.9506}\n",
      "epoch: 8 step: 938, loss is 0.43486487865448\n",
      "Eval result: epoch 8, metrics: {'accuracy': 0.9555}\n",
      "epoch: 9 step: 938, loss is 0.1941455900669098\n",
      "Eval result: epoch 9, metrics: {'accuracy': 0.9588}\n",
      "epoch: 10 step: 938, loss is 0.13441434502601624\n",
      "Eval result: epoch 10, metrics: {'accuracy': 0.9632}\n"
     ]
    }
   ],
   "source": [
    "trainer = Model(model, loss_fn=loss_fn, optimizer=optimizer, metrics={'accuracy'})\n",
    "\n",
    "trainer.fit(10, train_dataset, test_dataset, callbacks=[ckpt_callback, loss_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程中会打印loss值，loss值会波动，但总体来说loss值会逐步减小，精度逐步提高。每个人运行的loss值有一定随机性，不一定完全相同。\n",
    "\n",
    "通过模型运行测试数据集得到的结果，验证模型的泛化能力：\n",
    "\n",
    "1. 使用`model.eval`接口读入测试数据集。\n",
    "2. 使用保存后的模型参数进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9632}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = trainer.eval(test_dataset)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以在打印信息中看出模型精度数据，示例中精度数据达到95%以上，模型质量良好。随着网络迭代次数增加，模型精度会进一步提高。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "8c9da313289c39257cb28b126d2dadd33153d4da4d524f730c81a4aaccbd2ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
