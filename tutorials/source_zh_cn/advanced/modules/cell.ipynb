{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff738f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "[![下载Notebook](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_notebook.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/tutorials/zh_cn/advanced/modules/mindspore_cell.ipynb)&emsp;[![下载样例代码](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_download_code.png)](https://obs.dualstack.cn-north-4.myhuaweicloud.com/mindspore-website/notebook/master/tutorials/zh_cn/advanced/modules/mindspore_cell.py)&emsp;[![查看源文件](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source.png)](https://gitee.com/mindspore/docs/blob/master/tutorials/source_zh_cn/advanced/modules/cell.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4844a-1fed-47c4-8bbe-a63d3b7f0690",
   "metadata": {},
   "source": [
    "# 模型模块自定义\n",
    "\n",
    "## 基础用法示例\n",
    "\n",
    "神经网络模型由各种层(Layer)构成，MindSpore提供构造神经网络层的基础单元Cell，基于Cell进行神经网络封装。下面使用Cell构造经典模型AlexNet。\n",
    "\n",
    "![alextnet](https://gitee.com/mindspore/docs/blob/master/tutorials/source_zh_cn/advanced/modules/images/AlexNet.ppm)\n",
    "\n",
    "如图所示，AlexNet由5个卷积层与3个全连接层串联构成，我们使用`mindspore.nn`提供的神经网络层接口进行构造。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb173d1-10b6-4016-9fbd-98ad6c704211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09037240-de16-4971-96ff-938b4f506ab8",
   "metadata": {},
   "source": [
    "下面的代码展示了如何使用`nn.Cell`快速构造AlexNet。其中：\n",
    "\n",
    "- 顶层神经网络继承`nn.Cell`，为嵌套结构；\n",
    "- 每个神经网络层都是`nn.Cell`的子类；\n",
    "- `nn.SequentialCell`可以在定义顺序结构的模型时进行简化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31ff166-5812-4566-a880-b36b0cf3c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Cell):\n",
    "    def __init__(self, num_classes=1000, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.SequentialCell(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, pad_mode='pad', padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, pad_mode='pad', padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, pad_mode='pad', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, pad_mode='pad', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, pad_mode='pad', padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.SequentialCell(\n",
    "            nn.Dropout(1-dropout),\n",
    "            nn.Dense(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(1-dropout),\n",
    "            nn.Dense(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.shape[0], 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24827ae-9825-454b-a9fe-196fd74032ab",
   "metadata": {},
   "source": [
    "> 在定义模型的过程中，`construct`方法内可使用Python语法进行模型结构的任意构造，如条件、循环等控制流语句。但在进行即时编译(Just In Time)时，需通过编译器进行语法解析，此时存在语法限制，具体参考：[静态图语法支持](https://www.mindspore.cn/docs/zh-CN/master/note/static_graph_syntax_support.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d941d-cd99-4849-af0b-3914a8c7f018",
   "metadata": {},
   "source": [
    "完成模型构造后，我们构造一个单样本数据，将其送入实例化的AlexNet中，即可求得正向结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f1d8c0-934a-4147-b936-8390e214cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore import Tensor\n",
    "\n",
    "x = Tensor(np.random.randn(1, 3, 224, 224), mindspore.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962bfd47-94e6-4fee-baae-fd3bc0f0c537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "network = AlexNet()\n",
    "logits = network(x)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602723a-38e0-49f8-b3b8-e4dffd66fd39",
   "metadata": {},
   "source": [
    "## 更多使用场景\n",
    "\n",
    "除基础的网络结构构造外，我们分别对神经网络层(Layer)、损失函数(Loss)和优化器(Optimizer)，神经网络层需要的参数(Parameter)及其初始化方法(Initializer)的构造等场景进行详细介绍。\n",
    "\n",
    "- [参数与层](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/modules/layer.html)\n",
    "- [参数初始化](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/modules/initializer.html)\n",
    "- [损失函数](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/modules/loss.html)\n",
    "- [优化器](https://www.mindspore.cn/tutorials/zh-CN/master/advanced/modules/optimizer.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('mindspore')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c9da313289c39257cb28b126d2dadd33153d4da4d524f730c81a4aaccbd2ca7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
