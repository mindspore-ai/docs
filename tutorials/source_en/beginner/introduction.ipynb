{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Overview\n",
    "\n",
    "[![View-Source](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/resource/_static/logo_source_en.png)](https://gitee.com/mindspore/docs/blob/r1.7/tutorials/source_en/beginner/introduction.ipynb)\n",
    "\n",
    "The following describes the Huawei AI full-stack solution and introduces the position of MindSpore in the solution. Developers who are interested in MindSpore can visit the [MindSpore community](https://gitee.com/mindspore/mindspore) and click [Watch, Star, and Fork](https://gitee.com/mindspore/mindspore).\n",
    "\n",
    "## MindSpore Introduction\n",
    "\n",
    "MindSpore is a deep learning framework in all scenarios, aiming to achieve easy development, efficient execution, and all-scenario coverage.\n",
    "\n",
    "Easy development features friendly APIs and easy debugging. Efficient execution is reflected in computing, data preprocessing, and distributed training. All-scenario coverage means that the framework supports cloud, edge, and device scenarios.\n",
    "\n",
    "The following figure shows the overall MindSpore architecture:\n",
    "\n",
    "![MindSpore-arch](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/source_en/beginner/images/introduction2.png)\n",
    "\n",
    "- **ModelZoo**: ModelZoo provides available deep learning algorithm networks, and more developers are welcome to contribute new networks ([ModelZoo](https://gitee.com/mindspore/models)).\n",
    "- **Extend**: The expansion package of MindSpore expands the support of new fields, such as GNN/deep probabilistic programming/reinforcement learning, etc. We look forward to more developers to contribute and build together.\n",
    "- **Science**ï¼šMindScience is a scientific computing kits for various industries based on the converged MindSpore framefork. It contains the industry-leading datasets, basic network structures, high-precision pre-trained models, and pre-and post-processing tools that accelerate application development of the scientific computing ([More Information](https://mindspore.cn/mindscience/docs/en/r1.7/index.html)).\n",
    "- **Expression**: Python-based frontend expression and programming interfaces. In the future, more frontends based on C/C++ will be provided. Cangjie, Huawei's self-developed programming language frontend, is now in the pre-research phase. In addition, Huawei is working on interconnection with third-party frontends  to introduce more third-party ecosystems.\n",
    "- **Data**: Providing functions such as efficient data processing, common data sets loading and programming interfaces, and supporting users to flexibly define processing registration and pipeline parallel optimization.\n",
    "- **Compiler**: The core compiler of the layer, which implements three major functions based on the unified device-cloud MindIR, including hardware-independent optimization (type derivation, automatic differentiation, and expression simplification), hardware-related optimization (automatic parallelism, memory optimization, graph kernel fusion, and pipeline execution) and optimization related to deployment and inference (quantification and pruning).\n",
    "- **Runtime**: MindSpore runtime system, which covers the cloud-side host-side runtime system, the device-side and the lightweight runtime system of the smaller IoT.\n",
    "- **Insight**: Provides MindSpore's visual debugging and tuning tools, and supports users to debug and tune the training network ([More Information](https://mindspore.cn/mindinsight/docs/en/r1.7/index.html)).\n",
    "- **Armour**: For enterprise-level applications, security and privacy protection related enhancements, such as anti-robustness, model security testing, differential privacy training, privacy leakage risk assessment, data drift detection, etc. technology ([More Information](https://mindspore.cn/mindarmour/docs/en/r1.7/index.html)).\n",
    "\n",
    "### Execution Process\n",
    "\n",
    "With an understanding of the overall architecture of Ascend MindSpore, we can look at the overall coordination relationship between the various modules, as shown in the figure:\n",
    "\n",
    "![MindSpore](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/source_en/beginner/images/introduction4.png)\n",
    "\n",
    "As a full-scenario AI framework, MindSpore supports different series of hardware for end (mobile phone and IOT device), edge (base station and routing device), and cloud (server) scenarios, including Ascend series products, NVIDIA series products, Arm series Qualcomm Snapdragon, Huawei Kirin chips and other series of products.\n",
    "\n",
    "The blue box on the left is the MindSpore main framework, which mainly provides the basic API functions related to the training and verification of neural networks, and also provides automatic differentiation and automatic parallelism by default.\n",
    "\n",
    "Below the blue box is the MindSpore Data module, which can be used for data preprocessing, including data sampling, data iteration, data format conversion and other different data operations. In the process of training, many debugging and tuning problems will be encountered, so the MindSpore Insight module visualizes the data related to debugging and tuning such as loss curves, operator execution, and weight parameter variables, so as to facilitate users to debug and optimize during training.\n",
    "\n",
    "The simplest way to be AI security is from the perspective of attack and defense, for example, the attacker introduces malicious data during the training stage, affecting the inference ability of the AI model, so MindSpore launched the MindSpore Armour module to provide AN security mechanisms for MindSpore.\n",
    "\n",
    "The content above the blue box is closer to the users related to algorithm development, including storing a large number of AI algorithm model libraries ModelZoo, providing a development tool suite for different fields MindSpore DevKit, and a high-level expansion library MindSpore Extend, which is worth mentioning the scientific computing suite MindSciences in MindSpore Extend. For the first time, MindSpore explores the combination of scientific computing and deep learning, the combination of numerical computing and deep learning, and the support of electromagnetic simulation, drug molecule simulation and so on through deep learning.\n",
    "\n",
    "After the neural network model is trained, you can export the model or load the model that has been trained in MindSpore Hub. Then MindIR provides a unified IR format for the end cloud, which defines the logical structure of the network and the properties of the operators through the unified IR, and decouples the model file in the MindIR format with the hardware platform to achieve multiple deployments at one time. Therefore, as shown in the figure, the model is exported to different modules through IR to perform inference.\n",
    "\n",
    "### Design Philosophy\n",
    "\n",
    "- Support full-scenario collaboration\n",
    "\n",
    "    MindSpore is an industry-wide best practice. It provides data scientists and algorithm engineers with a unified interface for model training, inference, and export. It supports flexible deployment in different scenarios such as end, edge, and cloud, and promotes the prosperity and development in deep learning, scientific computing and other fields.\n",
    "\n",
    "- Provide Python programming normal form to simplify AI programming\n",
    "\n",
    "    MindSpore provides a Python programming normal form. Users can build complex neural network models using Python's native control logic, making AI programming easy.\n",
    "\n",
    "- Provide a unified coding method for PyNative graphs and static graphs\n",
    "\n",
    "    At present, there are two execution modes of mainstream deep learning frameworks, they are Graph mode and PyNative mode. Graph mode has high training performance but is difficult to debug. Although the Pynative mode is easier to debug than the static graph mode, it is difficult to execute efficiently. MindSpore provides a unified coding method for PyNative graphs and static graphs, which greatly increases their compatibility. Users do not need to develop multiple sets of codes, and can switch the mode only by changing one line of code. For example, users can set `context.set_context(mode=context.PYNATIVE_MODE)` to switch to the PyNative mode and set `context.set_context(mode=context.GRAPH_MODE)` to switch to the Graph mode, users can have an easier development, debugging and performance experience.\n",
    "\n",
    "- Use functional differentiable programming architecture and allow users to focus on the mathematical native expression of model algorithms\n",
    "\n",
    "    Neural network models are usually trained based on gradient descent algorithms, but the manual derivation process is complicated and the results are prone to errors. The Automatic Differentiation mechanism based on Source Code Transformation of MindSpore adopts a functional differentiable programming architecture, and provides a Python programming interface at the interface layer, including the expression of control flow. Users can focus on the mathematically native expression of the model algorithm without manual derivation.\n",
    "\n",
    "- Unify the coding method of single device and distributed training\n",
    "\n",
    "    With the increasing scale of neural network models and datasets, distributed parallel training has become a common practice in neural network training. However, the strategy selection and writing of distributed parallel training are very complicated, which seriously restricts the training efficiency of deep learning models. MindSpore unifies the coding methods of single device and distributed training. Developers do not need to write complex distributed strategies. They can implement distributed training by adding a small amount of code to the single device code. For example, setting `context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL)` can automatically establish a cost model, select an optimal parallel mode for users, improve the efficiency of neural network training, greatly reduce the threshold of AI development, and enable users to quickly implement model ideas.\n",
    "\n",
    "### API Level Structure\n",
    "\n",
    "To support network building, entire graph execution, subgraph execution, and single-operator execution, MindSpore provides users with three levels of APIs. In ascending order, these are Low-Level Python API, Medium-Level Python API, and High-Level Python API.\n",
    "\n",
    "![MindSpore API](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/master/tutorials/source_zh_cn/beginner/images/introduction3.png)\n",
    "\n",
    "- High-Level Python API\n",
    "\n",
    "  High-level APIs are at the first layer. Based on the medium-level API, these advanced APIs include training and inference management, mixed precision training, and debugging and optimization, enabling users to control the execution process of the entire network and implement training, inference, and optimization of the neural network. For example, by utilizing the Model API, users can specify the neural network model to be trained as well as related training settings, train the neural network model, and debug the neural network performance through the Profiler API.\n",
    "\n",
    "- Medium-Level Python API\n",
    "\n",
    "  Medium-level APIs are at the second layer, which encapsulates low-cost APIs and provides such modules as the network layer, optimizer, and loss function. Users can flexibly build neural networks and control execution processes through the medium-level API to quickly implement model algorithm logic. For example, users can call the Cell API to build neural network models and computing logic, add the loss function and optimization methods to the neural network model by using the loss module and Optimizer API, and use the dataset module to process data for model training and derivation.\n",
    "\n",
    "- Low-Level Python API\n",
    "\n",
    "  Low-level APIs are at the third layer, including tensor definition, basic operators, and automatic differential modules, enabling users to easily define tensors and perform derivative computation. For example, users can customize tensors by using the Tensor API, and use the GradOperation operator in the ops.composite module to calculate the derivative of the function at a specified position.\n",
    "\n",
    "## Introduction to Huawei Ascend AI Full-Stack Solution\n",
    "\n",
    "Ascend computing is a full-stack AI computing infrastructure and application based on the Ascend series processors. It includes the Ascend series chips, Atlas series hardware, CANN chip enablement, MindSpore AI framework, ModelArts, and MindX application enablement.\n",
    "\n",
    "Huawei Atlas AI computing solution is based on Ascend series AI processors and uses various product forms such as modules, cards, edge stations, servers, and clusters to build an all-scenario AI infrastructure solution oriented to device, edge, and cloud. It covers data center and intelligent edge solutions, as well as the entire inference and training processes in the deep learning field.\n",
    "\n",
    "- **Atlas series**: provides AI training, inference cards, and training servers ([learn more](https://e.huawei.com/en/products/cloud-computing-dc/atlas/)).\n",
    "- **CANN at heterogeneous computing architecture**: a driver layer that enables chips ([learn more](https://www.hiascend.com/en/software/cann)).\n",
    "- **MindSpore**: all-scenario AI framework ([learn more](https://www.mindspore.cn/en)).\n",
    "- **MindX SDK**: Ascend SDK that provides application solutions ([learn more](https://www.hiascend.com/en/software/mindx-sdk)).\n",
    "- **ModelArts**: HUAWEI CLOUD AI development platform ([learn more](https://www.huaweicloud.com/product/modelarts.html)).\n",
    "- **MindStudio**: E2E development toolchain that provides one-stop IDE for AI development ([learn more](https://www.hiascend.com/en/software/mindstudio)).\n",
    "\n",
    "For details, click [Huawei Ascend official website](https://e.huawei.com/en/products/servers/ascend).\n",
    "\n",
    "## Joining the Community\n",
    "\n",
    "Welcome every developer to the MindSpore community and contribute to this all-scenario AI framework.\n",
    "\n",
    "- **MindSpore official website**: provides comprehensive MindSpore information, including installation, tutorials, documents, community, resources, and news ([learn more](https://www.mindspore.cn/en)).\n",
    "- **MindSpore code**:\n",
    "\n",
    "    - [MindSpore Gitee](https://gitee.com/mindspore/mindspore): Top 1 Gitee open-source project in 2020, where you can track the latest progress of MindSpore by clicking Watch, Star, and Fork, discuss issues, and commit code.\n",
    "\n",
    "    - [MindSpore Github](https://github.com/mindspore-ai/mindspore): MindSpore code image of Gitee. Developers who are accustomed to using GitHub can learn MindSpore and view the latest code implementation here.\n",
    "\n",
    "- **MindSpore forum**: We are dedicated to serving every developer. You can find your voice in MindSpore, regardless of whether you are an entry-level developer or a master. Let's learn and grow together. ([Learn more](https://bbs.huaweicloud.com/forum/forum-1076-1.html))"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}