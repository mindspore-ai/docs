{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "执行主要有三种方式：单算子、普通函数和网络训练模型。\n",
    "\n",
    "> 本文档适用于GPU和Ascend环境。\n",
    "\n",
    "## 执行单算子\n",
    "\n",
    "执行单个算子，并打印相关结果。\n",
    "\n",
    "代码样例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.01647821  0.05310077  0.05310077  0.05310077  0.05118286]\n",
      "   [ 0.03007141  0.0657572   0.0657572   0.0657572   0.04350833]\n",
      "   [ 0.03007141  0.0657572   0.0657572   0.0657572   0.04350833]\n",
      "   [ 0.03007141  0.0657572   0.0657572   0.0657572   0.04350833]\n",
      "   [ 0.01847598  0.04713529  0.04713529  0.04713529  0.03720935]]\n",
      "\n",
      "  [[-0.03362034 -0.06124294 -0.06124294 -0.06124294 -0.04334928]\n",
      "   [-0.02676596 -0.08040315 -0.08040315 -0.08040315 -0.06846539]\n",
      "   [-0.02676596 -0.08040315 -0.08040315 -0.08040315 -0.06846539]\n",
      "   [-0.02676596 -0.08040315 -0.08040315 -0.08040315 -0.06846539]\n",
      "   [-0.00557975 -0.06808633 -0.06808633 -0.06808633 -0.08389233]]\n",
      "\n",
      "  [[-0.01602227  0.02266152  0.02266152  0.02266152  0.06030601]\n",
      "   [-0.06764769 -0.02966945 -0.02966945 -0.02966945  0.04861854]\n",
      "   [-0.06764769 -0.02966945 -0.02966945 -0.02966945  0.04861854]\n",
      "   [-0.06764769 -0.02966945 -0.02966945 -0.02966945  0.04861854]\n",
      "   [-0.06528193 -0.03500666 -0.03500666 -0.03500666  0.02858584]]\n",
      "\n",
      "  [[-0.03102187 -0.03846825 -0.03846825 -0.03846825 -0.00858424]\n",
      "   [-0.04270145 -0.070785   -0.070785   -0.070785   -0.05362675]\n",
      "   [-0.04270145 -0.070785   -0.070785   -0.070785   -0.05362675]\n",
      "   [-0.04270145 -0.070785   -0.070785   -0.070785   -0.05362675]\n",
      "   [-0.01230605 -0.04999261 -0.04999261 -0.04999261 -0.04718029]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "from mindspore import context, Tensor\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "\n",
    "conv = nn.Conv2d(3, 4, 3, bias_init='zeros')\n",
    "input_data = Tensor(np.ones([1, 3, 5, 5]).astype(np.float32))\n",
    "output = conv(input_data)\n",
    "print(output.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行普通函数\n",
    "\n",
    "将若干算子组合成一个函数，然后直接通过函数调用的方式执行这些算子，并打印相关结果，如下例所示。\n",
    "\n",
    "代码样例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3. 3.]\n",
      " [3. 3. 3.]\n",
      " [3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mindspore import context, Tensor\n",
    "import mindspore.ops as ops\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "\n",
    "def tensor_add_func(x, y):\n",
    "    z = ops.tensor_add(x, y)\n",
    "    z = ops.tensor_add(z, x)\n",
    "    return z\n",
    "\n",
    "x = Tensor(np.ones([3, 3], dtype=np.float32))\n",
    "y = Tensor(np.ones([3, 3], dtype=np.float32))\n",
    "output = tensor_add_func(x, y)\n",
    "print(output.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行网络模型\n",
    "\n",
    "MindSpore的Model接口是用于训练和验证的高级接口。可以将有训练或推理功能的layers组合成一个对象，通过调用train、eval、predict接口可以分别实现训练、推理和预测功能。\n",
    "\n",
    "用户可以根据实际需要传入网络、损失函数和优化器等初始化Model接口，还可以通过配置amp_level实现混合精度，配置metrics实现模型评估。\n",
    "\n",
    "在执行网络之前，先将所需要的数据集下载并解压缩到指定位置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-08 17:36:20--  https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip\n",
      "Resolving proxy-notebook.modelarts-dev-proxy.com (proxy-notebook.modelarts-dev-proxy.com)... 192.168.0.172\n",
      "Connecting to proxy-notebook.modelarts-dev-proxy.com (proxy-notebook.modelarts-dev-proxy.com)|192.168.0.172|:8083... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10754903 (10M) [application/zip]\n",
      "Saving to: ‘MNIST_Data.zip’\n",
      "\n",
      "MNIST_Data.zip      100%[===================>]  10.26M  41.0MB/s    in 0.3s    \n",
      "\n",
      "2020-12-08 17:36:20 (41.0 MB/s) - ‘MNIST_Data.zip’ saved [10754903/10754903]\n",
      "\n",
      "Archive:  MNIST_Data.zip\n",
      "   creating: ./datasets/MNIST_Data/test/\n",
      "  inflating: ./datasets/MNIST_Data/test/t10k-images-idx3-ubyte  \n",
      "  inflating: ./datasets/MNIST_Data/test/t10k-labels-idx1-ubyte  \n",
      "   creating: ./datasets/MNIST_Data/train/\n",
      "  inflating: ./datasets/MNIST_Data/train/train-images-idx3-ubyte  \n",
      "  inflating: ./datasets/MNIST_Data/train/train-labels-idx1-ubyte  \n",
      "./datasets/MNIST_Data/\n",
      "├── test\n",
      "│   ├── t10k-images-idx3-ubyte\n",
      "│   └── t10k-labels-idx1-ubyte\n",
      "└── train\n",
      "    ├── train-images-idx3-ubyte\n",
      "    └── train-labels-idx1-ubyte\n",
      "\n",
      "2 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "!wget -N https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip\n",
    "!unzip -o MNIST_Data.zip -d ./datasets\n",
    "!tree ./datasets/MNIST_Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行训练模型\n",
    "\n",
    "通过调用Model的train接口可以实现训练。\n",
    "\n",
    "代码样例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Training ==============\n",
      "epoch: 1 step: 375, loss is 2.2898183\n",
      "epoch: 1 step: 750, loss is 2.2777305\n",
      "epoch: 1 step: 1125, loss is 0.27802905\n",
      "epoch: 1 step: 1500, loss is 0.032973606\n",
      "epoch: 1 step: 1875, loss is 0.06105463\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore.dataset.vision import Inter\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as CT\n",
    "import mindspore.nn as nn\n",
    "from mindspore import context, Model\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.common.initializer import TruncatedNormal\n",
    "from mindspore.dataset.vision import Inter\n",
    "from mindspore.train.callback import LossMonitor, ModelCheckpoint, CheckpointConfig\n",
    "\n",
    "\n",
    "def create_dataset(data_path, batch_size=32, repeat_size=1,\n",
    "                   num_parallel_workers=1):\n",
    "    \"\"\"\n",
    "    create dataset for train or test\n",
    "    \"\"\"\n",
    "    # define dataset\n",
    "    mnist_ds = ds.MnistDataset(data_path)\n",
    "\n",
    "    resize_height, resize_width = 32, 32\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "    rescale_nml = 1 / 0.3081\n",
    "    shift_nml = -1 * 0.1307 / 0.3081\n",
    "\n",
    "    # define map operations\n",
    "    resize_op = CV.Resize((resize_height, resize_width), interpolation=Inter.LINEAR)  # Bilinear mode\n",
    "    rescale_nml_op = CV.Rescale(rescale_nml, shift_nml)\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    type_cast_op = CT.TypeCast(mstype.int32)\n",
    "\n",
    "    # apply map operations on images\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"label\", operations=type_cast_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=resize_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=rescale_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=rescale_nml_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=hwc2chw_op, num_parallel_workers=num_parallel_workers)\n",
    "\n",
    "    # apply DatasetOps\n",
    "    buffer_size = 10000\n",
    "    mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)  # 10000 as in LeNet train script\n",
    "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
    "    mnist_ds = mnist_ds.repeat(repeat_size)\n",
    "\n",
    "    return mnist_ds\n",
    "\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    \"\"\"weight initial for conv layer\"\"\"\n",
    "    weight = weight_variable()\n",
    "    return nn.Conv2d(in_channels, out_channels,\n",
    "                     kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                     weight_init=weight, has_bias=False, pad_mode=\"valid\")\n",
    "\n",
    "\n",
    "def fc_with_initialize(input_channels, out_channels):\n",
    "    \"\"\"weight initial for fc layer\"\"\"\n",
    "    weight = weight_variable()\n",
    "    bias = weight_variable()\n",
    "    return nn.Dense(input_channels, out_channels, weight, bias)\n",
    "\n",
    "\n",
    "def weight_variable():\n",
    "    \"\"\"weight initial\"\"\"\n",
    "    return TruncatedNormal(0.02)\n",
    "\n",
    "\n",
    "class LeNet5(nn.Cell):\n",
    "    \"\"\"\n",
    "    Lenet network\n",
    "\n",
    "    Args:\n",
    "        num_class (int): Num classes. Default: 10.\n",
    "        num_channel (int): Num channels. Default: 1.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor\n",
    "    Examples:\n",
    "        >>> LeNet(num_class=10)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_class=10, num_channel=1):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\n",
    "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.max_pool2d(self.relu(self.conv1(x)))\n",
    "        x = self.max_pool2d(self.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "\n",
    "    model_path = \"./models/ckpt/mindspore_run/\"\n",
    "    os.system(\"rm -rf {0}*.ckpt {0}*.meta {0}*.pb\".format(model_path))\n",
    "\n",
    "    ds_train_path = \"./datasets/MNIST_Data/train/\"\n",
    "    ds_train = create_dataset(ds_train_path, 32)\n",
    "\n",
    "    network = LeNet5(10)\n",
    "    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "    net_opt = nn.Momentum(network.trainable_params(), 0.01, 0.9)\n",
    "    config_ck = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=5)\n",
    "    ckpoint_cb = ModelCheckpoint(prefix=\"checkpoint_lenet\", directory=model_path, config=config_ck)\n",
    "    model = Model(network, net_loss, net_opt)\n",
    "\n",
    "    print(\"============== Starting Training ==============\")\n",
    "    model.train(1, ds_train, callbacks=[LossMonitor(375), ckpoint_cb], dataset_sink_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 示例中用到的MNIST数据集的获取方法，可以参照[实现一个图片分类应用](https://www.mindspore.cn/tutorial/training/zh-CN/r1.1/quick_start/quick_start.html)的下载数据集部分，下同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 使用PyNative模式调试， 请参考[使用PyNative模式调试](https://www.mindspore.cn/tutorial/training/zh-CN/r1.1/advanced_use/debug_in_pynative_mode.html)， 包括单算子、普通函数和网络训练模型的执行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行推理模型\n",
    "\n",
    "通过调用Model的eval接口可以实现推理。为了方便评估模型的好坏，可以在Model接口初始化的时候设置评估指标Metric。\n",
    "\n",
    "Metric是用于评估模型好坏的指标。常见的主要有Accuracy、Fbeta、Precision、Recall和TopKCategoricalAccuracy等，通常情况下，一种模型指标无法全面的评估模型的好坏，一般会结合多个指标共同作用对模型进行评估。\n",
    "\n",
    "常用的内置评估指标：\n",
    "\n",
    "- `Accuracy`（准确率）：是一个用于评估分类模型的指标。通俗来说，准确率是指我们的模型预测正确的结果所占的比例。 公式：$$Accuracy = （TP+TN）/（TP+TN+FP+FN）$$\n",
    "\n",
    "- `Precision`（精确率）：在被识别为正类别的样本中，确实为正类别的比例。公式：$$Precision = TP/(TP+FP)$$\n",
    "\n",
    "- `Recall`（召回率）：在所有正类别样本中，被正确识别为正类别的比例。 公式：$$Recall = TP/(TP+FN)$$\n",
    "\n",
    "- `Fbeta`（调和均值）：综合考虑precision和recall的调和均值。\n",
    "公式：$$F_\\beta = (1 + \\beta^2) \\cdot \\frac{precisiont \\cdot recall}{(\\beta^2 \\cdot precision) + recall}$$\n",
    "\n",
    "- `TopKCategoricalAccuracy`（多分类TopK准确率）：计算TopK分类准确率。\n",
    "\n",
    "代码样例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Starting Testing ==============\n",
      "============== {'Accuracy': 0.960136217948718, 'Precision': array([0.95763547, 0.98059965, 0.99153439, 0.93333333, 0.97322348,\n",
      "       0.99385749, 0.98502674, 0.93179724, 0.8974359 , 0.97148676])} ==============\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as CT\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "import mindspore.nn as nn\n",
    "from mindspore import context, Model\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindspore.dataset.vision import Inter\n",
    "from mindspore.nn import Accuracy, Precision\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "\n",
    "class LeNet5(nn.Cell):\n",
    "    \"\"\"\n",
    "    Lenet network\n",
    "\n",
    "    Args:\n",
    "        num_class (int): Num classes. Default: 10.\n",
    "        num_channel (int): Num channels. Default: 1.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor\n",
    "    Examples:\n",
    "        >>> LeNet(num_class=10)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_class=10, num_channel=1):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\n",
    "        self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "        self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.max_pool2d(self.relu(self.conv1(x)))\n",
    "        x = self.max_pool2d(self.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def create_dataset(data_path, batch_size=32, repeat_size=1,\n",
    "                   num_parallel_workers=1):\n",
    "    \"\"\"\n",
    "    create dataset for train or test\n",
    "    \"\"\"\n",
    "    # define dataset\n",
    "    mnist_ds = ds.MnistDataset(data_path)\n",
    "\n",
    "    resize_height, resize_width = 32, 32\n",
    "    rescale = 1.0 / 255.0\n",
    "    shift = 0.0\n",
    "    rescale_nml = 1 / 0.3081\n",
    "    shift_nml = -1 * 0.1307 / 0.3081\n",
    "\n",
    "    # define map operations\n",
    "    resize_op = CV.Resize((resize_height, resize_width), interpolation=Inter.LINEAR)  # Bilinear mode\n",
    "    rescale_nml_op = CV.Rescale(rescale_nml, shift_nml)\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    type_cast_op = CT.TypeCast(mstype.int32)\n",
    "\n",
    "    # apply map operations on images\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"label\", operations=type_cast_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=resize_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=rescale_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=rescale_nml_op, num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(input_columns=\"image\", operations=hwc2chw_op, num_parallel_workers=num_parallel_workers)\n",
    "\n",
    "    # apply DatasetOps\n",
    "    buffer_size = 10000\n",
    "    mnist_ds = mnist_ds.shuffle(buffer_size=buffer_size)  # 10000 as in LeNet train script\n",
    "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
    "    mnist_ds = mnist_ds.repeat(repeat_size)\n",
    "\n",
    "    return mnist_ds\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "\n",
    "    model_path = \"./models/ckpt/mindspore_run/\"\n",
    "    ds_eval_path = \"./datasets/MNIST_Data/test/\"\n",
    "    network = LeNet5(10)\n",
    "    net_loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "    repeat_size = 1\n",
    "    net_opt = nn.Momentum(network.trainable_params(), 0.01, 0.9)\n",
    "    model = Model(network, net_loss, net_opt, metrics={\"Accuracy\": Accuracy(), \"Precision\": Precision()})\n",
    "\n",
    "    print(\"============== Starting Testing ==============\")\n",
    "    param_dict = load_checkpoint(model_path+\"checkpoint_lenet-1_1875.ckpt\")\n",
    "    load_param_into_net(network, param_dict)\n",
    "    ds_eval = create_dataset(ds_eval_path, 32, repeat_size)\n",
    "\n",
    "    acc = model.eval(ds_eval, dataset_sink_mode=True)\n",
    "    print(\"============== {} ==============\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，\n",
    "`load_checkpoint`：通过该接口加载CheckPoint模型参数文件，返回一个参数字典。\n",
    "`checkpoint_lenet-1_1875.ckpt`：保存的CheckPoint模型文件名称。\n",
    "`load_param_into_net`：通过该接口把参数加载到网络中。\n",
    "\n",
    "> `checkpoint_lenet-1_1875.ckpt`文件的保存方法，可以参考[实现一个图片分类应用](https://www.mindspore.cn/tutorial/training/zh-CN/r1.1/quick_start/quick_start.html)的训练网络部分。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore-1.0.1",
   "language": "python",
   "name": "mindspore-1.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}