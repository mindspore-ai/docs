{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center/>加载文本数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MindSpore提供的`mindspore.dataset`模块可以帮助用户构建数据集对象，分批次地读取文本数据。同时，在各个数据集类中还内置了数据处理和数据分词算子，使得数据在训练过程中能够像经过pipeline管道的水一样源源不断地流向训练系统，提升数据训练效果。\n",
    "\n",
    "此外，MindSpore还支持分布式场景数据加载，用户可以在加载数据集时指定分片数目，具体用法参见[数据并行模式加载数据集](https://www.mindspore.cn/tutorial/training/zh-CN/r1.0/advanced_use/distributed_training_ascend.html#id6)。\n",
    "\n",
    "下面，本教程将简要演示如何使用MindSpore加载和处理文本数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整体流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 准备环节。\n",
    "- 加载数据集。\n",
    "- 数据处理。\n",
    "- 数据分词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备环节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入`mindspore.dataset`和`mindspore.dataset.text`模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备所需数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 在jupyter工作目录下创建`./datasets/loading_text_dataset/docs/`目录，本次体验所用的数据集存放在该目录下。\n",
    "2. 准备文本数据，内容如下;\n",
    "\n",
    "```\n",
    "Welcome to Beijing\n",
    "北京欢迎您！\n",
    "我喜欢English!\n",
    "```\n",
    "3. 创建`tokenizer.txt`文件并复制以上文本数据到该文件中，将该文件存放在`./datasets/loading_text_dataset/docs/`目录下，目录结构如下所示：\n",
    "\n",
    "```\n",
    "datasets/\n",
    "└── loading_text_dataset\n",
    "    └── docs\n",
    "        └── tokenizer.txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MindSpore目前支持加载文本领域常用的经典数据集和多种数据存储格式下的数据集，用户也可以通过构建自定义数据集类实现自定义方式的数据集加载。各种数据集的详细加载方法，可参考编程指南中[数据集加载](https://mindspore.cn/doc/programming_guide/zh-CN/r1.0/dataset_loading.html)章节。\n",
    "\n",
    "下面演示使用`MindSpore.dataset`模块中的`TextFileDataset`类加载数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 配置数据集目录，创建数据集对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = './datasets/loading_text_dataset/docs/tokenizer.txt'\n",
    "dataset = ds.TextFileDataset(DATA_FILE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 创建字典迭代器，通过迭代器获取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Beijing\n",
      "北京欢迎您！\n",
      "我喜欢English!\n"
     ]
    }
   ],
   "source": [
    "for data in dataset.create_dict_iterator(output_numpy=True):\n",
    "    print(text.to_str(data['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MindSpore目前支持的数据处理算子及其详细使用方法，可参考编程指南中[数据处理](https://www.mindspore.cn/doc/programming_guide/zh-CN/r1.0/pipeline.html)章节。\n",
    "\n",
    "在生成`dataset`对象后可对其进行数据处理操作，比如`SlidingWindow`、`shuffle`等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SlidingWindow\n",
    "\n",
    "    下面演示使用`SlidingWindow`对文本数据进行切片操作。\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. 加载数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[\"大\",\"家\",\"早\",\"上\",\"好\"]]\n",
    "dataset_slide = ds.NumpySlicesDataset(inputs, column_names=['text'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.原始数据输出效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['大', '家', '早', '上', '好']\n"
     ]
    }
   ],
   "source": [
    "for data in dataset_slide.create_dict_iterator(output_numpy=True):\n",
    "    print(text.to_str(data['text']).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. 执行切片操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_slide = dataset_slide.map(operations=text.SlidingWindow(2,0),input_columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. 执行之后输出效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['大', '家'], ['家', '早'], ['早', '上'], ['上', '好']]\n"
     ]
    }
   ],
   "source": [
    "for data in dataset_slide.create_dict_iterator(output_numpy=True):\n",
    "    print(text.to_str(data['text']).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- shuffle\n",
    "\n",
    "    下面演示在加载数据集时使用`shuffle`对文本数据进行混洗操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 加载数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"a\",\"b\",\"c\",\"d\"]\n",
    "dataset_shuffle = ds.NumpySlicesDataset(inputs, column_names=['text'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 数据输出效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "c\n",
      "b\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for data in dataset_shuffle.create_dict_iterator(output_numpy=True):\n",
    "    print(text.to_str(data['text']).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MindSpore目前支持的数据分词算子及其详细使用方法，可参考编程指南中[分词器](https://www.mindspore.cn/doc/programming_guide/zh-CN/master/tokenizer.html)章节。\n",
    "\n",
    "下面演示使用`WhitespaceTokenizer`分词器来分词，该分词是按照空格来进行分词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 创建`tokenizer`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 执行操作`tokenizer`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(operations=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 创建字典迭代器，通过迭代器获取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome', 'to', 'Beijing']\n",
      "['北京欢迎您！']\n",
      "['我喜欢English!']\n"
     ]
    }
   ],
   "source": [
    "for data in dataset.create_dict_iterator(num_epochs=1,output_numpy=True):\n",
    "    print(text.to_str(data['text']).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
